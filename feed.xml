<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title></title>
  
  
  <link href="/feed.xml" rel="self"/>
  
  <link href="https://osujin.github.io/"/>
  <updated>2018-09-19T04:28:10.986Z</updated>
  <id>https://osujin.github.io/</id>
  
  <author>
    <name>sujin Oh</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>kibana 를 이용하여 시각화 하기 3</title>
    <link href="https://osujin.github.io/2018/09/05/ELK/comute/kibana%20%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC%20%EC%8B%9C%EA%B0%81%ED%99%94%20%ED%95%98%EA%B8%B0-3/"/>
    <id>https://osujin.github.io/2018/09/05/ELK/comute/kibana 를 이용하여 시각화 하기-3/</id>
    <published>2018-09-05T06:29:51.000Z</published>
    <updated>2018-09-19T04:28:10.986Z</updated>
    
    <content type="html"><![CDATA[<p>앞선 두개의 글에서 kibana를 활용하여 데이터를 시각화 하는 방법에 대해 알아보았다.</p><p>이번글에서는 kibana가 제공하는 여러가지 시각화 툴을 이용하여 다양한 형태의 통계자료를 만들어 보고자 한다.</p><p>Line 차트를 이용해 통근 소요시간에 대한 그래프를 그려보았는데 평균적으로 출근과 퇴근하는데 걸리는 시간을 계산해보았다.</p><p>Visualize - Data - Metric 순서대로 들어가서 <strong>estimated</strong> 값을 기준으로 평균값을 계산해주면 된다. </p><p>그런데 한가지 주의 할 점이 외근,야근이나 약속등으로 바로 집으로 퇴근 하지 않은 경우엔 데이터가 누락되어 정확한 계산이 나오기 힘들었다. </p><p>그래서 가장 출퇴근 비율이 높은 버스 정류장의 시점과 종점을 기준으로 삼사 해당 구간의 통근 시간만 계산해 보기로 하였다.</p><p>우선 <strong>estimated</strong>를 기준으로 평균값을 계산한다음 filter로 <strong>travelStation</strong>을 선택하여 정류장 이름을 선택해주니 다음과 같은 결과가 나왔다.</p><p><img src="/image/2018/ELK_comute/평균계산.png" alt=""></p><p>통근시간 분석을 계획했을때 궁금했던점이 비가오거나 눈이 올때와 같이 기상상태가 좋지 않은 경우 교통체증이 좀더 심하게 느껴지는 경향이 있었는데 기상정보 통계 데이터와 나의 통근 시간도 관계가 있지 않을까 생각이 들어 기상정보 데이터도 수집하여 ES에 넣고 시각화를 해보았다.</p><p>그결과 다음과 같은 Dashboard를 만들 수 있었다.</p><p><img src="/image/2018/ELK_comute/출퇴근 소요시간 - Kibana.png" alt=""></p><p>강수량과 통근시간의 상관 관계를 한눈에 파악하긴 힘들었지만 비가 오는날이 평소보단 출근시간이 좀더 걸렸다는건 알 수 있었다. </p><p>아직은 1차원 적인 접근방법을 통하였기 때문에 단순이 데이터를 시각화 하는 수준이지만 앞으로 이를 활용하여 미래를 예측 할 수 있지 않을까 하는 생각도 들었다.</p><p>과거의 데이터를 기반으로 출근 시간이 대략 얼마정도 걸릴 것인지 어떤 교통수단이 효율적인지등 좀더 실생활에서 체감 할 수있는 데이터 활용이 가능 할 것같다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;앞선 두개의 글에서 kibana를 활용하여 데이터를 시각화 하는 방법에 대해 알아보았다.&lt;/p&gt;
&lt;p&gt;이번글에서는 kibana가 제공하는 여러가지 시각화 툴을 이용하여 다양한 형태의 통계자료를 만들어 보고자 한다.&lt;/p&gt;
&lt;p&gt;Line 차트를 이
      
    
    </summary>
    
      <category term="Elastic Search" scheme="https://osujin.github.io/categories/Elastic-Search/"/>
    
    
      <category term="ELK,elastic search,시각화" scheme="https://osujin.github.io/tags/ELK-elastic-search-%EC%8B%9C%EA%B0%81%ED%99%94/"/>
    
  </entry>
  
  <entry>
    <title>kibana 를 이용하여 시각화 하기 2</title>
    <link href="https://osujin.github.io/2018/09/04/ELK/comute/kibana%20%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC%20%EC%8B%9C%EA%B0%81%ED%99%94%20%ED%95%98%EA%B8%B0-2/"/>
    <id>https://osujin.github.io/2018/09/04/ELK/comute/kibana 를 이용하여 시각화 하기-2/</id>
    <published>2018-09-04T12:12:31.000Z</published>
    <updated>2018-09-19T04:28:10.981Z</updated>
    
    <content type="html"><![CDATA[<p>지난 글에서는 ES에 저장된 데이터에 몇개의 필드를 추가하는 방법에 대해 알아 보았다.</p><p>이번글에서는 수집된 데이터를 이용해 그래프를 통한 시각화를 해보도록 하자.</p><hr><p>Kibana 왼쪽 메뉴에서 <strong>Visualize</strong>를 선택한 뒤 “+” 버튼을 누르면 다음과 같은 화면이나온다.</p><p><img src="/image/2018/ELK_comute/차트종륭.png" alt=""></p><p>Line 차트를 선택하고 차트에 사용되어질 데이터가 들어있는 index를 선택해주면 그래프를 그릴수 있는 화면이 나오는데 앞서 만든 데이터를 활용하여 그래프를 그려주면 된다.</p><p>먼저 설정해줄것은 Metrics 으로 Y 축의 기준이 되는 값을 설정해 주어야한다. </p><p>Y축을 통근하는데 걸린 시간의 총 합으로 하기로하고 “Y-Axis” 왼쪽에 있는 화살표를 눌러 <strong>Aggregation</strong>항목을 sum 으로 선택하고 field는 <strong>estimated</strong>를 선택해준다.</p><p> estimated 는 앞선 글에서 설명했듯이 하차시간 - 승차시간을 계산하여 만들어진 값을 새로운 필드로 추가한 값이다.</p><p>다음으로 Buckets(X 축)을 설정 해줄 차례이다. 마찬가지로 “X-Axis”를 선택해 <strong>Aggregation</strong>항목을 Data Histogram 으로 선택하고 Field는 @timestamp 를 선택해준다.</p><p>Interval은 daily로 선택하여 하루를 기준으로 출근,퇴근 소요시간의 총 합을 계산하도록 한다.</p><p><img src="/image/2018/ELK_comute/통근 소요시간.png" alt=""></p><p>위 그림이 최종적으로 만들어진 그래프이다. 중간에 값이 없는 구간이 있는데 이때는 아마 다른 교통카드를 사용중이라 데이터가 없었던것 같다.</p><p>이번에는 출근과 퇴근 시간을 나누어서 확인해 보도록 하자.</p><p>Buckets 항목에 하단에 <strong>Add sub-buckets</strong> 항목을 누르고 <strong>Split Series</strong>를 선택하여 <strong>Sub Aggregation</strong> =&gt; <strong>Terms</strong> 로 선택하고 Field는 이전 글에서 생성한 <strong>commuteType</strong> Field를 선택해주자</p><p><img src="/image/2018/ELK_comute/통근종류.png" alt=""></p><p>그러면 위 그림과 같이 출근,퇴근 그래프가 각각 생성되어진다.</p><p>출근, 퇴근 시간만 각각 보고 싶으면 상단의 필터기능을 이용해  commuteType 을 기준으로 필터를 적용해주면 된다.</p><p>다음 글에서는 여러가지 차트를 만들어 dashboard를 구성해보도록 하겠다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;지난 글에서는 ES에 저장된 데이터에 몇개의 필드를 추가하는 방법에 대해 알아 보았다.&lt;/p&gt;
&lt;p&gt;이번글에서는 수집된 데이터를 이용해 그래프를 통한 시각화를 해보도록 하자.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Kibana 왼쪽 메뉴에서 &lt;strong&gt;Visu
      
    
    </summary>
    
      <category term="Elastic Search" scheme="https://osujin.github.io/categories/Elastic-Search/"/>
    
    
      <category term="ELK,elastic search,시각화" scheme="https://osujin.github.io/tags/ELK-elastic-search-%EC%8B%9C%EA%B0%81%ED%99%94/"/>
    
  </entry>
  
  <entry>
    <title>kibana 를 이용하여 시각화 하기 1</title>
    <link href="https://osujin.github.io/2018/09/03/ELK/comute/kibana%20%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC%20%EC%8B%9C%EA%B0%81%ED%99%94%20%ED%95%98%EA%B8%B0-1/"/>
    <id>https://osujin.github.io/2018/09/03/ELK/comute/kibana 를 이용하여 시각화 하기-1/</id>
    <published>2018-09-03T12:11:58.000Z</published>
    <updated>2018-09-19T04:34:48.855Z</updated>
    
    <content type="html"><![CDATA[<p>앞서 logstash 를 이용해 source data를 가공하여 ES에 저장하였다.</p><p>데이터를 ES에 저장한 뒤에는 꼭 index를 생성해주어야 하는데 logstash가 데이터를 ES 에 저장하는 순간 ES 상에는 index 가 생성되고 mapping 까지 완료된 상태이다.</p><p>그러나 kibana 를 통해 접속해보면 index가 나와있지 않는데 kibana가 관리하는 index를 ES로 부터 불러와야 한다.</p><p>kibana 에 접속하여 왼쪽 메뉴에서 Management 를 누르고 kibana 항목의 index patterns 를 클릭한다.</p><p>그리고 + Create Index Pattern 을 선택하여 logstash 에서 사용한 index 명을 입력해주고 “Next step” 을 클릭한다음 Time Filter를 @Timestamp 를 선택하여 index를 생성해준다.</p><p>이제 kibana를 이용해 저장된 데이터를 분석하고 시각화를 해보도록 한다.</p><p>ES에 저장된 데이터중 하나의 document를 살펴보자</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"_index"</span>: <span class="string">"office_work"</span>,</span><br><span class="line">  <span class="attr">"_type"</span>: <span class="string">"doc"</span>,</span><br><span class="line">  <span class="attr">"_id"</span>: <span class="string">"xsMrx2UBHYmbdMUbWuZ_"</span>,</span><br><span class="line">  <span class="attr">"_version"</span>: <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"_score"</span>: <span class="literal">null</span>,</span><br><span class="line">  <span class="attr">"_source"</span>: &#123;</span><br><span class="line">    <span class="attr">"@timestamp"</span>: <span class="string">"2018-09-02T07:11:27.000Z"</span>,</span><br><span class="line">    <span class="attr">"charge "</span>: <span class="string">" 1,200원 "</span>,</span><br><span class="line">    <span class="attr">"Boarding_Station"</span>: <span class="string">"신사사거리.가로"</span>,</span><br><span class="line">    <span class="attr">"host"</span>: <span class="string">"osujin-MBP"</span>,</span><br><span class="line">    <span class="attr">"date"</span>: <span class="string">"2018-09-01T15:00:00.000Z"</span>,</span><br><span class="line">    <span class="attr">"message"</span>: <span class="string">"2018.09.02,신사사거리.가로,16:11:27,지하철2호선강남,16:19:09,\" 1,200원 \",버스\r"</span>,</span><br><span class="line">    <span class="attr">"classify"</span>: <span class="string">"버스"</span>,</span><br><span class="line">    <span class="attr">"Boarding_clock"</span>: <span class="string">"2018-09-02T07:11:27.000Z"</span>,</span><br><span class="line">    <span class="attr">"@version"</span>: <span class="string">"1"</span>,</span><br><span class="line">    <span class="attr">"Exit_Station"</span>: <span class="string">"지하철2호선강남"</span>,</span><br><span class="line">    <span class="attr">"Exit_clock"</span>: <span class="string">"2018-09-02T07:19:09.000Z"</span>,</span><br><span class="line">    <span class="attr">"path"</span>: <span class="string">"/Users/osujin12/Downloads/bus.csv"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"fields"</span>: &#123;</span><br><span class="line">    <span class="attr">"date"</span>: [</span><br><span class="line">      <span class="string">"2018-09-01T15:00:00.000Z"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"@timestamp"</span>: [</span><br><span class="line">      <span class="string">"2018-09-02T07:11:27.000Z"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"Boarding_clock"</span>: [</span><br><span class="line">      <span class="string">"2018-09-02T07:11:27.000Z"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"Exit_clock"</span>: [</span><br><span class="line">      <span class="string">"2018-09-02T07:19:09.000Z"</span></span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"sort"</span>: [</span><br><span class="line">    <span class="number">1536304287000</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>_source 하위에 있는 field는 원본 데이터인 csv 파일에 logstash 파 추가로 생성한 field 정보가 붙여져 있다. 그리고 logstash 에서 filter plugin 으로 수정한 필드는 fields 하위 영역에 포함되어 있다.</p><p>이제 위 데이터를 가지고 출퇴근 소요 시간을 계산하려고 한다.</p><p>간단히 생각해서 <strong>하차시간 - 승차 시간 = 통근 소요시간</strong> 이라는 공식이 생각나는데 아예 통근 소요시간 필드를 하나 추가해 주면 여러므로 이용할때가 많을거라 생각이 들었다. </p><p>구글을 열심히 검색해본 결과 index에 새로운 field를 생성하는 방법이 나와 있었는데  Management 를 누르고 kibana 항목의 index patterns 를 클릭하면 총 3개의 탭이 나온다. Fields, Scripted fields, Source filters 가 있는데 이중 <strong>Scripted fields</strong> 를 클릭하고 <strong>Add scripted field</strong> 를 해준다.</p><p>painless 라는 문법을 가지고 새로운 field 데이터를 생성하는 방법이 있는데 하차시간 - 승차 시간 을 계산한 값을 새로운 필드로 생성하고자 한다.</p><p><img src="/image/2018/ELK_comute/새로운 필드 생성.png" alt=""></p><p>통근 시간계산하는 스크립트는 다음과 같다. Boarding_clock, Exit_clock 는 date type 이므로 millisecond 로 데이터 형태를 변형 할 수 있고 이를 1시간을 분으로 표현한 60으로 나누어 주면 통근 소요시간이 분단위로 계산되어진다. </p><p>원본데이터중 쓰레기 값이 있는 경우가 있기때문에 음수값이 나오는 경우는 0을 리턴하도록 하였다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def time = (doc[&apos;Exit_clock&apos;].value.getMillis() - doc[&apos;Boarding_clock&apos;].value.getMillis())/60000.0;</span><br><span class="line"></span><br><span class="line">if(time &gt; 0)&#123;</span><br><span class="line">return time;</span><br><span class="line">&#125;else&#123;</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>필드를 추가한 김에 몇가지 정보를 더 추가해 보자.</p><p>원본데이터를 보면 승차역,하차역이 따로 되어있어 하나로 합쳐진 필드명이 있으면 좋을것 같다. </p><p>간단히 두개의 필드명을 합쳐주면 된다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">doc[&apos;Boarding_Station.keyword&apos;].value + &apos;-&apos; + doc[&apos;Exit_Station.keyword&apos;].value</span><br></pre></td></tr></table></figure><p>그리고 계산한 통근 시간이 출근인지 퇴근인지 표시해주는 필드도 필요하다. 이경우는 조금 복잡하였는데 기본적으로 ES는 timezone 이 UTC 로 기본 셋팅되어 있어 timezone을 변경하지 않으면 시간이 꼬여서 계산하기 힘들어진다.</p><p>timezone은 Asia/Seoul 로 바꿔주고  승차시간이 13시 이전이면 출근으로 간주하는 스크립트를 만들어 줬다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def commuteType = LocalDateTime.ofInstant(Instant.ofEpochMilli(doc[&apos;Boarding_clock&apos;].value.millis),ZoneId.of(&apos;Asia/Seoul&apos;)).getHour();</span><br><span class="line"></span><br><span class="line">if(commuteType &lt; 13)&#123;</span><br><span class="line">return &quot;출근&quot;;</span><br><span class="line">&#125;else&#123;</span><br><span class="line">return &quot;퇴근&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>이로써 시각화에 필요한 데이터를 만드는데 얼추 끝난것 같다. </p><p>다음 글에서는 Kibana 에서 제공하는 시각화 도구를 이용하여 통근시간에 대한 다양한 분석을 시도 해보도록 하겠다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;앞서 logstash 를 이용해 source data를 가공하여 ES에 저장하였다.&lt;/p&gt;
&lt;p&gt;데이터를 ES에 저장한 뒤에는 꼭 index를 생성해주어야 하는데 logstash가 데이터를 ES 에 저장하는 순간 ES 상에는 index 가 생성되
      
    
    </summary>
    
      <category term="Elastic Search" scheme="https://osujin.github.io/categories/Elastic-Search/"/>
    
    
      <category term="ELK,elastic search,시각화" scheme="https://osujin.github.io/tags/ELK-elastic-search-%EC%8B%9C%EA%B0%81%ED%99%94/"/>
    
  </entry>
  
  <entry>
    <title>logstash를 이용하여 source 데이터 가공하기</title>
    <link href="https://osujin.github.io/2018/08/26/ELK/comute/logstash%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC%20source%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EA%B0%80%EA%B3%B5%ED%95%98%EA%B8%B0/"/>
    <id>https://osujin.github.io/2018/08/26/ELK/comute/logstash를 이용하여 source 데이터 가공하기/</id>
    <published>2018-08-26T14:31:14.000Z</published>
    <updated>2018-09-19T04:24:58.586Z</updated>
    
    <content type="html"><![CDATA[<p>이전 글에서 ES에 대한 소개와 ELK 설치에 대해 알아보았다.</p><p>본글에서는 source data를 가공하고 logstash 를 이용하여 ES에 저장하는 방법에 대해 알아보고자 한다.</p><h2 id="Source-Data-편집"><a href="#Source-Data-편집" class="headerlink" title="Source Data 편집"></a>Source Data 편집</h2><p>1편에서 언급했던 교통카드 이용 정보는 다음과 같이 총 9개의 필드가 있다.</p><table><thead><tr><th>사용일</th><th>카드번호</th><th>승차역(입구)</th><th>승차시간</th><th>하차역(출구)</th><th>하차시간</th><th>사용금액</th><th>구분</th><th>결제예정일자</th></tr></thead><tbody><tr><td></td></tr></tbody></table><p>내가 필요한 필드는 ‘사용일’, ‘승차역’, ‘승차시간’, ‘하차역’, ‘하차시간’,’사용금액’, ‘구분’ 정도라서 해당 필드만 선택하여 새로운 엑셀자료를 만들어 주었다.</p><p>그리고 한글 필드명은 여러모로 불편하므로 필드명도 영문명으로 바꿔주었다.</p><p><img src="/image/2018/ELK_comute/변환 교통카드 이용내역.png" alt=""></p><p>새로 만든 엑셀파일을 csv 형태로 저장해주면 된다.</p><h2 id="Logstash를-이용해-ES에-데이터-저장하기"><a href="#Logstash를-이용해-ES에-데이터-저장하기" class="headerlink" title="Logstash를 이용해 ES에 데이터 저장하기"></a>Logstash를 이용해 ES에 데이터 저장하기</h2><p>위 수정된 source data를 보면 Boarding_Time(승차시간) , Exit_Time(하차시간) 필드의 데이터가 HH:mm:ss 형태로 되어있어 년,월,일을 알 수가 없다. </p><p>그래서 date 필드의 날짜 정보와 합쳐 “yyyy.MM.dd HH:mm:ss” 형태의 date field 를 생성하고 ES에 저장할때 Date type으로 인식하도록 해주는 작업이 필요하다.</p><p>이 작업들은 logstash 설정파일을 통해 가능한대 </p><ul><li>입력</li><li>가공</li><li>출력</li></ul><p>총 3개의 필드로 나뉘어져 있다. 하나씩 알아가 보자.</p><h3 id="입력"><a href="#입력" class="headerlink" title="입력"></a>입력</h3><p>먼저 csv 형태로 만든 파일을 읽어오는 부분이다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  file &#123;</span><br><span class="line">    path =&gt; &quot;/Users/abc/Downloads/bus.csv&quot;</span><br><span class="line">    start_position =&gt; &quot;beginning&quot;</span><br><span class="line">   sincedb_path =&gt; &quot;/dev/null&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>input 부분에 파일형태의 데이터를 입력받는 file플러그인을 사용하였다.</p><h3 id="가공-filter"><a href="#가공-filter" class="headerlink" title="가공(filter)"></a>가공(filter)</h3><p>filter 영역은 활용성이 정말 무긍무진 하다. 새로운 필드를 추가할 수도 있고 제거할 수도 있고 기존 데이터의 형식을 바꾸는등 다양한 활용방법이 있는데 내가 필요한 기능은 위에서 언급했듯이 Boarding_Time(승차시간) , Exit_Time(하차시간) 필드의 데이터 형식을 바꾸고 date type으로 변환 하는것이다.</p><p>먼저 해주어야 할 것은 csv 파일의 header 정보를 제공해주고 separator를 설정해주는것이다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">csv &#123;</span><br><span class="line">      separator =&gt; &quot;,&quot;</span><br><span class="line">     columns =&gt; [&quot;date&quot;,&quot;Boarding_Station&quot;,&quot;Boarding_Time&quot;,&quot;Exit_Station&quot;,&quot;Exit_Time&quot;,&quot;charge &quot;,&quot;classify&quot;]</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h4 id="시간정보-변경"><a href="#시간정보-변경" class="headerlink" title="시간정보 변경"></a>시간정보 변경</h4><p>기존 승차시간 =&gt; 07:51:07</p><p>변환된 승차시간 =&gt; 2018.03.02 07:51:07</p><p>위 작업은 mutate plugin을 이용한다. 기존 date, Boarding_Time, Exit_Time 필드를 이용해 새로운 필드인 Boarding_clock, Exit_clock 필드를 생성해 주고 기존 Boarding_Time, Exit_Time 두 필드는 삭제를 해주었다. date 필드는 검색에 사용될거라 남겨뒀다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mutate &#123;</span><br><span class="line">    add_field =&gt; &#123;</span><br><span class="line">      &quot;Boarding_clock&quot; =&gt; &quot;%&#123;date&#125; %&#123;Boarding_Time&#125;&quot;</span><br><span class="line">      &quot;Exit_clock&quot; =&gt; &quot;%&#123;date&#125; %&#123;Exit_Time&#125;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    remove_field =&gt; [&quot;Exit_Time&quot;, &quot;Boarding_Time&quot;]</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>그리고 새로 생성한 두개의 필드와 date 필드의 type을 Date 형식으로 변환 해주어야 한다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">date &#123; </span><br><span class="line">      match =&gt; [&quot;Boarding_clock&quot;, &quot;yyyy.MM.dd HH:mm:ss&quot;] </span><br><span class="line">      target =&gt; &quot;Boarding_clock&quot;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  date &#123; </span><br><span class="line">      match =&gt; [&quot;Exit_clock&quot;, &quot;yyyy.MM.dd HH:mm:ss&quot;] </span><br><span class="line">      target =&gt; &quot;Exit_clock&quot;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  date &#123; </span><br><span class="line">      match =&gt; [&quot;date&quot;, &quot;yyyy.MM.dd&quot;] </span><br><span class="line">      target =&gt; &quot;date&quot;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>마지막으로 @timestamp 필드 정보를 Boarding_clock 필드로 치환한다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">date &#123; </span><br><span class="line">      match =&gt; [&quot;Boarding_clock&quot;, &quot;yyyy.MM.dd HH:mm:ss&quot;] </span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="출력"><a href="#출력" class="headerlink" title="출력"></a>출력</h3><p>마지막으로 입력받은 데이터를 출력하는 부분이다. stdout 형태로 출력하여 수정된 데이터 형태를 보며 수정할 수 있고 수정작업이 끝나면 바로 ES로 데이터를 보낼 수 있다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; &quot;http://localhost:9200&quot;</span><br><span class="line">    index =&gt; &quot;office_work&quot;</span><br><span class="line"> &#125;</span><br><span class="line">stdout &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>다음 글에서는 kibana 를 이용해서 시각화 하는 방법에 대해 알아보자.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;이전 글에서 ES에 대한 소개와 ELK 설치에 대해 알아보았다.&lt;/p&gt;
&lt;p&gt;본글에서는 source data를 가공하고 logstash 를 이용하여 ES에 저장하는 방법에 대해 알아보고자 한다.&lt;/p&gt;
&lt;h2 id=&quot;Source-Data-편집&quot;&gt;
      
    
    </summary>
    
      <category term="Elastic Search" scheme="https://osujin.github.io/categories/Elastic-Search/"/>
    
    
      <category term="ELK,elastic search,시각화" scheme="https://osujin.github.io/tags/ELK-elastic-search-%EC%8B%9C%EA%B0%81%ED%99%94/"/>
    
  </entry>
  
  <entry>
    <title>Spring-boot JPA 이용하기</title>
    <link href="https://osujin.github.io/2018/08/23/spring-boot/Spring-boot%20JPA%20%EC%9D%B4%EC%9A%A9%ED%95%98%EA%B8%B0/"/>
    <id>https://osujin.github.io/2018/08/23/spring-boot/Spring-boot JPA 이용하기/</id>
    <published>2018-08-23T04:00:32.000Z</published>
    <updated>2018-08-23T04:51:18.164Z</updated>
    
    <content type="html"><![CDATA[<p>spring boot JPA 기본 설정이 끝났으면 실제 DB를 불러와 데이터를 조회 해보자</p><p>먼저 해야할 일은 properties 파일에 설정을 추가해주는 것이다.</p><p>resource 폴더 하위에 보면 application.properties 파일이 기본적으로 생성되어있을 것이다.</p><p>개인적으로 properties 형식 보단 yml을 선호하여 yml 파일 기준으로 설정셋팅법을 알아보자.</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  profiles:</span></span><br><span class="line"><span class="attr">    active:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">    driver-class-name:</span> <span class="string">org.postgresql.Driver</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  profiles:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">  datasource:</span></span><br><span class="line"><span class="attr">    url:</span> <span class="attr">jdbc:postgresql://localhost:5432/test</span></span><br><span class="line"><span class="attr">    username:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">    password:</span> <span class="string">test123</span></span><br><span class="line"><span class="attr">  jpa:</span></span><br><span class="line"><span class="attr">      show-sql:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>위와 같이 접속할 데이터베이스 정보를 적어주고 jpa를 이용하여 쿼리를 호출할때 로그상에 SQL형식으로 출력되도록 jpa 설정도 추가해준다.</p><p>다음으로 Repository 인터페이스를 생성하여 DB Table에 접근하도록 한다.</p><p>적당한 위치에 인터페이스를 생성하면 되는데 “CrudRepository” 를 상속받도록한다.</p><p>CrudRepository 의 parameter는 table entity , primary key type 을 넣어준다.</p><p>그리고 조회하고자 하는 조건의 컬럼명으로 조회 method를 하나 생성하면되는데 phone 컬럼을 이용해서 데이터를 조회한다고 가정했을 경우 findBy[Column 명] 을 넣어주면 된다. 메소드명을 만들때는 Camel 표기법에 의거해 컬럼 앞글자는 대문자로 써주면 된다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> osj_book</span><br><span class="line">(</span><br><span class="line">  <span class="keyword">id</span>    <span class="built_in">serial</span>  <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">  age   <span class="built_in">varchar</span>(<span class="number">255</span>),</span><br><span class="line">  <span class="keyword">name</span>  <span class="built_in">varchar</span>(<span class="number">255</span>),</span><br><span class="line">  phone <span class="built_in">integer</span> <span class="keyword">not</span> <span class="literal">null</span></span><br><span class="line">    <span class="keyword">constraint</span> osj_book_phone_pk</span><br><span class="line">    primary <span class="keyword">key</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.osj.Demo1.JPADemo.Repo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.osj.Demo1.JPADemo.Entity.OsjBookEntity;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.repository.CrudRepository;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Repository;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Repository</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">OsjBookRepository</span> <span class="keyword">extends</span> <span class="title">CrudRepository</span>&lt;<span class="title">OsjBookEntity</span>,<span class="title">String</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function">List&lt;OsjBookEntity&gt; <span class="title">findByPhone</span><span class="params">(String name)</span></span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Repository 인터페이스까지 만들었으면 데이터를 조회해볼 차례이다.</p><p>조회는 Junit Test를 이용해 진행해보자.</p><p>test 폴더 하위에 생성된 ~Tests.java 파일을 열어 몇가지 Annontaion을 추가해줘야한다.</p><ul><li>@RunWith(SpringRunner.class) : SpringJUnit4ClassRunner에 대한 정보를 담고 있다.</li><li>@DataJpaTest    : JPA 테스트를 진행</li><li>@AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE)    : properties에 설정된 DB와 연동</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RunWith</span>(SpringRunner.class)</span><br><span class="line"><span class="meta">@DataJpaTest</span></span><br><span class="line"><span class="meta">@AutoConfigureTestDatabase</span>(replace = AutoConfigureTestDatabase.Replace.NONE)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JpaDemoApplicationTests</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">OsjBookRepository osjBookRepository;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">contextLoads</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">List&lt;OsjBookEntity&gt; osjBookEntities = osjBookRepository.findByPhone(<span class="string">"010"</span>);</span><br><span class="line"></span><br><span class="line">System.out.println(osjBookEntities.size());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>이렇게 junit 테스트 모델을 만든후 실행을 하면 JPA를 통해 table entity가 만들어지고 table이 객체화 되어 사용되어질수 있다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;spring boot JPA 기본 설정이 끝났으면 실제 DB를 불러와 데이터를 조회 해보자&lt;/p&gt;
&lt;p&gt;먼저 해야할 일은 properties 파일에 설정을 추가해주는 것이다.&lt;/p&gt;
&lt;p&gt;resource 폴더 하위에 보면 application.p
      
    
    </summary>
    
      <category term="Java" scheme="https://osujin.github.io/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>Spring-boot JPA 초기 설정방법</title>
    <link href="https://osujin.github.io/2018/08/23/spring-boot/Spring-boot%20JPA%20%EC%B4%88%EA%B8%B0%20%EC%84%A4%EC%A0%95%EB%B0%A9%EB%B2%95%20/"/>
    <id>https://osujin.github.io/2018/08/23/spring-boot/Spring-boot JPA 초기 설정방법 /</id>
    <published>2018-08-23T02:00:32.000Z</published>
    <updated>2018-08-23T04:59:41.749Z</updated>
    
    <content type="html"><![CDATA[<p>Spring boot 를 이용하여 신규 프로젝트를 진행할 때 JPA를 활용하는 방법에 대해 적어본다.</p><p>제일 먼저 프로젝트를 신규로 생성 해주어야 하는데 <a href="https://start.spring.io" target="_blank" rel="noopener">https://start.spring.io</a> 페이지에서 제공되는 템플릿을 이용하여 maven 프로젝트를 하나 생성해 주었다.</p><p><img src="/image/2018/08/JPA/springInit.png" alt=""></p><p>기본 프로젝트를 생성 하였다면 Intellij 에서 제공하는 JPA entity 생성 plugin을 이용하여 DataBase를 연동해주면 된다</p><h2 id="1-Intellij-에-DB연동해주기"><a href="#1-Intellij-에-DB연동해주기" class="headerlink" title="1. Intellij 에 DB연동해주기"></a>1. Intellij 에 DB연동해주기</h2><p>Intellij 오른쪽 사이바 탭에 DataBase 메뉴를 선택해 “+” 버튼을 눌러 사용고자 하는 DB를 연동해주면 된다.</p><h2 id="2-project-setting에-들어가-Hibernate-Module-추가해주기"><a href="#2-project-setting에-들어가-Hibernate-Module-추가해주기" class="headerlink" title="2. project setting에 들어가 Hibernate Module 추가해주기"></a>2. project setting에 들어가 Hibernate Module 추가해주기</h2><p>JPA를 사용하기 위한 표준 기술인 Hibernate를 이용한다</p><p>프로젝트를 우클릭하고 project setting 메뉴에 들어가 아래 사진과 같이  Hibernate 모듈을 추가해주고 “+” 버튼을 눌러 hibernate.cfg.xml 파일을 하나 생성해준다</p><p><img src="/image/2018/08/JPA/hibernate 1.png" alt=""></p><p>정상적으로 생성 되었으면 아래 그림처럼 왼쪽 사이드바 메뉴에 persistence 라는 메뉴가 생기고 이를 눌러보면 추가된 Hibernate module 이 표시된다.</p><p><img src="/image/2018/08/JPA/hibernate 2.png" alt=""></p><h2 id="3-Hibernate-와-DB-연동하기"><a href="#3-Hibernate-와-DB-연동하기" class="headerlink" title="3. Hibernate 와 DB 연동하기"></a>3. Hibernate 와 DB 연동하기</h2><p>아래 그림과 같이 Database를 hibernate와 연동해주어야 하는데 “By Database Schema” 메뉴를 클릭하면 팝업 창으로 Import Database Schema 창이 뜬다.</p><p><img src="/image/2018/08/JPA/hibernate3.png" alt=""> </p><p>1 번에서 연동해주었던 DB를 choose Data Source에 선택하고 package 에는 DB table을 java 파일로 변환 한다음 저장될 결로를 선택해주면 된다.</p><p>그리고 중앙에 위치한 table List에서 내가하고자한 Table을 선택해 주고 OK 버튼을 누르면 설정된 package 경로에 java 파일이 생성된다. </p><p><img src="/image/2018/08/JPA/hibernate4.png" alt=""></p><p>추가적으로 프로젝트 초기 생성시 jdbc 플러그인을 pom에 따로 추가해주지 않았는데 자신이 사용하고자 하는 DB plugin을 pom에 추가해주면 된다.</p><p>여기까지가 Spring boot JPA을 활용하기 위한 초기 설정과정이다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Spring boot 를 이용하여 신규 프로젝트를 진행할 때 JPA를 활용하는 방법에 대해 적어본다.&lt;/p&gt;
&lt;p&gt;제일 먼저 프로젝트를 신규로 생성 해주어야 하는데 &lt;a href=&quot;https://start.spring.io&quot; target=&quot;_bl
      
    
    </summary>
    
      <category term="Java" scheme="https://osujin.github.io/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>ELK 소개 및 간략 셋팅방법</title>
    <link href="https://osujin.github.io/2018/08/22/ELK/comute/ELK%20%EC%86%8C%EA%B0%9C%20%EB%B0%8F%20%EA%B0%84%EB%9E%B5%20%EC%85%8B%ED%8C%85%EB%B0%A9%EB%B2%95/"/>
    <id>https://osujin.github.io/2018/08/22/ELK/comute/ELK 소개 및 간략 셋팅방법/</id>
    <published>2018-08-22T05:38:11.000Z</published>
    <updated>2018-09-19T04:30:38.489Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/image/2018/ELK_comute/217A9C4E58C504202D.png" alt=""></p><p>지난 글에서는 Elastic Search를 이용해 통근시간을 분석해 보자는 목표를 세우고 필요한 데이터를 수집하는 방법에 대해 알아 보았다.</p><p>이번글에선 데이터 분석에 활용되는 ELK(Elasitc Search, Logstash, Kibana)의 간략한 소개와 설치 및 셋팅 방법에 대해 알아보자.</p><p>우선 rawData 분석에 활용되는 Elastic Search에 대해 알아보자.</p><p>Elastic Search(이하 ES)는 Lucene 이란 자바 오픈소스 검색 라이브러리 기반으로 만들어진 검색 엔진으로 JSON 형식으로 데이터를 저장하여 관리한다.</p><p>RESTful API 를 기반으로 다양한 형태의 데이터를 정형화 하여 검색 및 통계등을 낼 수 있는 강력한 도구이다. 또한 분산과 확장에 용이하여 대량의 데이터도 빠르게 처리가 가능하다.</p><p>처음 ES를 접한것은 log 데이터 분석에 활용된다는 얘기를 듣고 어떻게 활용되는지 보고 지나갔었는데 다시 ES를 공부해보니 데이터 분석에 상당히 막강한 도구로 활용 할 수 있다는 생각이 들었다.</p><h3 id="설치방법"><a href="#설치방법" class="headerlink" title="설치방법"></a>설치방법</h3><p>기본적으로 설치하는 방법에는 apt,yum 등을 이용한 설치 방법과 binary 형태로 제공되는 압축파일을 받아 실행 하는 방법이 있는데 처음에는 압축파일을 다운받아 테스트해보길 권장한다. </p><p>yum등을 이용한 설치 방법은 로그파일 위치,각종 설정 파일의 위치를 파악하기 힘들고 문제가 생겼을 경우 쉽게 수정하기 힘들수 있다. </p><h3 id="설치-파일"><a href="#설치-파일" class="headerlink" title="설치 파일"></a>설치 파일</h3><ul><li>Elastic Search : 데이터 저장 및 분석</li><li>Logstash : source Data를 ES에 저장하는 tool</li><li>Kibana : ES에 저장된 데이터를 관리해주고 시각화 해주는 UI tool</li></ul><p>위 3개의 설치파일 모두 Elastic Search 공식 홈페이지에서 최신 버전으로 다운받아 사용하길 권장한다.</p><p>ES를 사용하기 앞서 몇가지 용어를 알고 갈게 있다.</p><ul><li>index : 검색의 기준이 되는 단위로 rdb로 치면 database와 유사하다. </li><li>type : rdb의 table과 같은 역활. </li><li>document : 데이터의 구성 단위로써 하나의 json object로 이루어져있다. rdb에서의 row의 개념으로 보면 된다.</li><li>mapping : 데이터 필드의 type을 명시하는 것으로 table schema 를 생성하는것과 유사하다.</li></ul><p>아직 ES 클러스터를 구성하여 운용할 필요가 없기에 단일 노드로 구성해서 사용하였는데 추후 대량의 데이터와 index가 늘어나면 클러스터를 구성해볼 필요성이 있을것 같다.</p><p>다음 글에서는 1탄에서 준비한 source data(대중교통 이용정보)를 가공하여 ES에 저장하는 방법에 대해 알아보겠다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/image/2018/ELK_comute/217A9C4E58C504202D.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;지난 글에서는 Elastic Search를 이용해 통근시간을 분석해 보자는 목표를 세우고 필요한 데이터를 수집하는 방
      
    
    </summary>
    
      <category term="Elastic Search" scheme="https://osujin.github.io/categories/Elastic-Search/"/>
    
    
      <category term="ELK,elastic search,시각화" scheme="https://osujin.github.io/tags/ELK-elastic-search-%EC%8B%9C%EA%B0%81%ED%99%94/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Search를 통근시간 분석 목표설정</title>
    <link href="https://osujin.github.io/2018/08/11/ELK/comute/Elastic%20Search%EB%A5%BC%20%ED%86%B5%EA%B7%BC%EC%8B%9C%EA%B0%84%20%EB%B6%84%EC%84%9D%20%EB%AA%A9%ED%91%9C%EC%84%A4%EC%A0%95/"/>
    <id>https://osujin.github.io/2018/08/11/ELK/comute/Elastic Search를 통근시간 분석 목표설정/</id>
    <published>2018-08-11T02:39:25.000Z</published>
    <updated>2018-09-19T04:17:48.611Z</updated>
    
    <content type="html"><![CDATA[<p>ElasticSearch를 보고있던중 이걸로 뭘 해야 할지 고민하던중 평소 극심한 출퇴근길 혼잡에 시달렸는데 나의 출퇴근길에 대한 통계를 내보면 재밌을것 같다는 생각이 들었다.</p><p><img src="/image/2018/ELK_comute/네이버 교통정보.png" alt=""></p><p>보통 위 그림처럼 네이버,다음,티맵 등에서 제공하는 교통정보는 개인에게 특화된 정보가 아니라 어는정도 정확 하긴하지만 좀더 개인에게 특화된 교통정보를 제공 해주면 좋을것 같다는 생각이들어 오직 ‘나’를 위한 교통정보 서비스를 분석해보자 한다.</p><p>그래서 생각했던 분석 결과는 </p><ol><li>출근 소요시간</li><li>퇴근 소요시간</li><li>일자별 통근 시간의 변화</li><li>날씨와 통근시간 상관관계</li></ol><p>위 4개정도 정보만 파악 하는것을 목표로 하였다. </p><p>분석을 위해 가장 중요한 것이 source data 수집인데 평소 대중교통을 이용해 출퇴근을 하기에 교통카드 기록이 남아 있을거라 생각하고 사용중인 신용카드의 교통카드 사용 이력을 출력해보았다.</p><p><img src="/image/2018/ELK_comute/교통카드 이용내역.png" alt=""></p><p>위와 같이 단말기에 카드를 찍은 _시간_ 과 <em>승차역</em> <em>하차역</em> 정보가 정확이 나온다. 이정도 정보만 있어도 출퇴근 시간을 계산하는데는 문제가 없어 보인다.</p><p><img src="/image/2018/ELK_comute/그래프1.png" alt=""></p><p>대략 위와 같은 모양의 그래프를 그려 출,퇴근에 걸리는 시간과 구간별 소요시간 최대,최소 값등을 분석해본다.</p><p>다음 글에서는 ELK(Elastic Search, Logstash, Kibana)의 간략한 소개와 설치방법 및 셋팅 방법을 알아본다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ElasticSearch를 보고있던중 이걸로 뭘 해야 할지 고민하던중 평소 극심한 출퇴근길 혼잡에 시달렸는데 나의 출퇴근길에 대한 통계를 내보면 재밌을것 같다는 생각이 들었다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/image/2018/ELK_comut
      
    
    </summary>
    
      <category term="Elastic Search" scheme="https://osujin.github.io/categories/Elastic-Search/"/>
    
    
      <category term="ELK,elastic search,시각화" scheme="https://osujin.github.io/tags/ELK-elastic-search-%EC%8B%9C%EA%B0%81%ED%99%94/"/>
    
  </entry>
  
  <entry>
    <title>Linux 서버에서 VPN 자동접속 하는방법</title>
    <link href="https://osujin.github.io/2018/06/21/Linux%20%EC%84%9C%EB%B2%84%EC%97%90%EC%84%9C%20VPN%20%EC%9E%90%EB%8F%99%EC%A0%91%EC%86%8D%20%ED%95%98%EB%8A%94%EB%B0%A9%EB%B2%95/"/>
    <id>https://osujin.github.io/2018/06/21/Linux 서버에서 VPN 자동접속 하는방법/</id>
    <published>2018-06-21T05:18:40.000Z</published>
    <updated>2018-06-21T09:01:56.762Z</updated>
    
    <content type="html"><![CDATA[<p>Linux 에서 VPN 접속 끊어지면 자동으로 reconnect 하는 스크립트 <strong>nmcli</strong> 명령어를 사용하였다</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">while [ "true" ]</span><br><span class="line">do</span><br><span class="line">        VPNCON=$(nmcli con show | grep 'VPN' | cut -f1 -d " ")</span><br><span class="line">        if [[ $VPNCON != "VPN" ]]; then</span><br><span class="line">                echo "Disconnected, trying to reconnect..."</span><br><span class="line">                (sleep 1s &amp;&amp; nmcli con up uuid 5f359e9f-010e-43ca-a3a0-25787c9b1359)</span><br><span class="line">        else</span><br><span class="line">                echo "Already connected !"</span><br><span class="line">        fi</span><br><span class="line">        sleep 30</span><br><span class="line">done</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Linux 에서 VPN 접속 끊어지면 자동으로 reconnect 하는 스크립트 &lt;strong&gt;nmcli&lt;/strong&gt; 명령어를 사용하였다&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;g
      
    
    </summary>
    
      <category term="기타" scheme="https://osujin.github.io/categories/%EA%B8%B0%ED%83%80/"/>
    
    
      <category term="Linux" scheme="https://osujin.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>logstash와 kafka 연동시 Multiple Topic 사용하기</title>
    <link href="https://osujin.github.io/2018/06/20/ELK/kafka-logstash/"/>
    <id>https://osujin.github.io/2018/06/20/ELK/kafka-logstash/</id>
    <published>2018-06-20T07:52:29.000Z</published>
    <updated>2018-09-19T04:11:41.461Z</updated>
    
    <content type="html"><![CDATA[<p>ELK 를 구축할때 kafka 로 프로세스별 log 데이터를 밀어넣은 다음 kafka - logstash 를 연동하여 ElasticSearch로 보내도록 구현중이다.</p><p>logstash 에서 여러개의 kafka Topic 을 처리하는 방법에 대해서 정리한 내용이다</p><p>A123 process =&gt; topic : A1</p><p>B123 process =&gt; topic : A2</p><p>C123 process =&gt; topic : A3</p><p>이런식으로 3개의 프로세스의 로그가 각각 다른 토픽에 저장되어있다.</p><p>ES(ElasticSearch)에는 다음과 같이 저장하려고 한다  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">index : server-log-[@date]</span><br><span class="line">- type</span><br><span class="line">  - A1-log</span><br><span class="line">  - A2-log</span><br><span class="line">  - A3-log</span><br></pre></td></tr></table></figure><p>logstash 에서 여러개의 topic 을 불러오는건 다음과 같다</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; &quot;192.168.202.148:9092&quot;</span><br><span class="line">        topics =&gt; [&quot;topic1&quot;,&quot;topic2&quot;]</span><br><span class="line">        group_id =&gt; &quot;logstash&quot;</span><br><span class="line">        consumer_threads =&gt; 2</span><br><span class="line">        decorate_events =&gt; true</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><p>위 topic 부분에 리스트([]) 형식으로 불러올 topic 을 넣어주면 된다.</p><p>문제는 topic 들을 각각 다른 ES type으로 분류하여 저장하는것이다.</p><p>topic 이름으로 구분하여 ES에 저장할때 사용되는 type 을 지정하고 싶은데 topic 을 구분할 수 있는 방법이 topic 명 말고는 없다.</p><p>그래서 logstash config 파일에 output 부분에서 topic 명으로 분기를 만들어 주기로 했는데…</p><blockquote><p>Removal of mapping types &gt;&gt;  <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.0/removal-of-types.html#removal-of-types" target="_blank" rel="noopener">multiple type 불가</a></p></blockquote><p>그렇다.. ES 6 버전부터는 index 당 한개의 type 만 생성이 가능하다.</p><p>그전에 input - kafka 안쪽에 “decorate_events =&gt; true” 설정을 꼭 넣어주자 그래야 topic 을 불러올수가 있다.</p><p>type을 여러개 만들면 이와같은 오류가 발생한다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Rejecting mapping update to [index1-2018.06.20] as the final mapping would have more than 1 type</span><br></pre></td></tr></table></figure><p>공식 문서에는 document_type을 생성하여 기존 type을 대체하라고 했는데 나는 그냥 원본 데이터에 새로 pName 필드를 추가하여 구분하는 방식으로 해보았다</p><p>최종 왼성된 config 설정은 아래와 같다</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; &quot;192.168.202.148:9092&quot;</span><br><span class="line">        topics =&gt; [&quot;topic1&quot;,&quot;topic2&quot;]</span><br><span class="line">        group_id =&gt; &quot;logstash&quot;</span><br><span class="line">        consumer_threads =&gt; 2</span><br><span class="line">        decorate_events =&gt; true     </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line"> if [@metadata][kafka][topic] == &quot;topic1&quot; &#123;</span><br><span class="line">        mutate &#123;</span><br><span class="line">                add_field =&gt; &#123;&apos;pName&apos; =&gt; &apos;topic1&apos;&#125;</span><br><span class="line">        &#125;</span><br><span class="line"> &#125;</span><br><span class="line">if [@metadata][kafka][topic] == &quot;topic2&quot; &#123;</span><br><span class="line">        mutate &#123;</span><br><span class="line">                add_field =&gt; &#123;&apos;pName&apos; =&gt; &apos;topic2&apos;&#125;</span><br><span class="line">        &#125;</span><br><span class="line"> &#125;</span><br><span class="line">  json &#123;</span><br><span class="line">    source =&gt; &quot;message&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">elasticsearch &#123;</span><br><span class="line">    hosts =&gt; [&quot;127.0.0.1:9200&quot;]</span><br><span class="line">    index =&gt; &quot;index-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">    document_type =&gt; &quot;logs&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>if [@metadata][kafka][topic] 를 이용하여 topic 을 불러와 새로운 필드를 추가하는 방식으로 프로세스별 로그를 구분하도록 하였다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ELK 를 구축할때 kafka 로 프로세스별 log 데이터를 밀어넣은 다음 kafka - logstash 를 연동하여 ElasticSearch로 보내도록 구현중이다.&lt;/p&gt;
&lt;p&gt;logstash 에서 여러개의 kafka Topic 을 처리하는 방
      
    
    </summary>
    
      <category term="Elastic Search" scheme="https://osujin.github.io/categories/Elastic-Search/"/>
    
    
      <category term="kafka" scheme="https://osujin.github.io/tags/kafka/"/>
    
      <category term="logstash" scheme="https://osujin.github.io/tags/logstash/"/>
    
      <category term="ElasticSearch" scheme="https://osujin.github.io/tags/ElasticSearch/"/>
    
  </entry>
  
  <entry>
    <title>MemoryCalendar_V1</title>
    <link href="https://osujin.github.io/2018/04/20/MemoryCalendar-V1/"/>
    <id>https://osujin.github.io/2018/04/20/MemoryCalendar-V1/</id>
    <published>2018-04-20T07:05:23.000Z</published>
    <updated>2018-04-20T05:56:17.369Z</updated>
    
    <content type="html"><![CDATA[<p>대학교 재학 시절 졸업작품으로 만들었던 MemoryCalendar 라는 제품의 V2 버전을 제작하기전에 초기 버전에 대한 간단한 리뷰를 작성하려고 한다.</p><p>제품 개발 컨센은 다음과 같았다.</p><p><img src="/image/2018/04/MC_V1-1.png" alt="사진1"></p><p>흔히 사용하는 탁상달력에 LED 모듈을 달아 자체제작한 스마트폰 달력 App과 연동하여 LED를 제어하고자 하는것이 가장 큰 목표였다.</p><p>추가적으로 LCD 모둘과의 페이스북 계정을 연동하여 과거의 오늘 사진을 LCD로 보여주는 액자기능도 제공하였다.</p><h1 id="프로젝트-구성도"><a href="#프로젝트-구성도" class="headerlink" title="프로젝트 구성도"></a>프로젝트 구성도</h1><p><img src="/image/2018/04/MC_V1-2.jpg" alt="사진2"></p><h1 id="각-모듈을-구성하는-핵심요소"><a href="#각-모듈을-구성하는-핵심요소" class="headerlink" title="각 모듈을 구성하는 핵심요소"></a>각 모듈을 구성하는 핵심요소</h1><h4 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h4><pre><code>- Arduino와 서버의 지속적인 연결을 위해 Websocket(Node.js)을 사용하여 동기화.- redis를 사용하여 빠른 데이터 접근 → 실시간으로 데이터를 주고받음.- WebSocket 헤더에 User_ID와 Client type을  추가하여 서버에서 구분.- Python으로 구현한 구글 검색 기반의 Crawler를 통한 관심사 이미지 검색.</code></pre><h4 id="Arduino-달력"><a href="#Arduino-달력" class="headerlink" title="Arduino(달력)"></a>Arduino(달력)</h4><pre><code>- Websocket을 이용하여 서버와 통신.- App에서 설정한 LED정보를 받음.- JSON array parsing을 통해 LED 데이터 추출</code></pre><h4 id="Raspberry-pi-액자"><a href="#Raspberry-pi-액자" class="headerlink" title="Raspberry pi(액자)"></a>Raspberry pi(액자)</h4><pre><code>- Websocket(Node.js)을 이용하여 서버와 통신하고 image url 수신.- Node.js를 이용하여 image를 다운로드.- Linux fbi 기능을 통해 image를 Display.</code></pre><h4 id="Android"><a href="#Android" class="headerlink" title="Android"></a>Android</h4><pre><code>- Facebook API를 이용한 자동 로그인과 과거 데이터 추출.- Picasso 라이브러리를 사용하여 실시간 이미지 로딩.- Websocket을 이용하여 서버와 통신.- 등록된 일정, LED정보, 관심사 설정 값들을 서버로 송신 및 동기화.</code></pre><p>최종적으로 왼성된 제품은 아래와 같다.</p><p><img src="/image/2018/04/IMG_0335.JPG" alt="사진3"></p><p>마지막으로 최종 제작된 제품설명 동영상을 첨부한다.</p><div class="video-container"><iframe src="//www.youtube.com/embed/DlM6_rVv0bw" frameborder="0" allowfullscreen></iframe></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;대학교 재학 시절 졸업작품으로 만들었던 MemoryCalendar 라는 제품의 V2 버전을 제작하기전에 초기 버전에 대한 간단한 리뷰를 작성하려고 한다.&lt;/p&gt;
&lt;p&gt;제품 개발 컨센은 다음과 같았다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/image/2
      
    
    </summary>
    
      <category term="MemoryCalendar" scheme="https://osujin.github.io/categories/MemoryCalendar/"/>
    
    
  </entry>
  
  <entry>
    <title>mybatis foreach를 이용해 insert batch 처리하기</title>
    <link href="https://osujin.github.io/2018/01/16/mybatis-foreach%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%B4-insert-batch-%EC%B2%98%EB%A6%AC%ED%95%98%EA%B8%B0/"/>
    <id>https://osujin.github.io/2018/01/16/mybatis-foreach를-이용해-insert-batch-처리하기/</id>
    <published>2018-01-16T08:46:22.000Z</published>
    <updated>2018-04-04T05:56:15.855Z</updated>
    
    <content type="html"><![CDATA[<p>30만정도 되는 데이터를 insert 해야하는데 for문을 이용한 단순 반복문으로 실행하니 insert가 안된다.</p><p>그래서 Mapper xml 에서 <foreach> 테그를 이용하여 대량의 데이터를 insert 하는 방법을 적어둔다.</foreach></p><p><strong>java code</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">SqlSession sqlSession = <span class="keyword">null</span>;</span><br><span class="line"> List&lt;table&gt;</span><br><span class="line">  tableList;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">              sqlSession = getSqlSessionFactory().openSession(<span class="keyword">false</span>);</span><br><span class="line">              Mapper table = sqlSession.getMapper(Mapper.class);</span><br><span class="line">              Mapper.insert(tableList);<span class="comment">//List를 넘겨준다.</span></span><br><span class="line">          &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">              sqlSession.commit();</span><br><span class="line">          &#125;</span><br></pre></td></tr></table></figure><p>위와 같이 List를 Mapper로 전달해주고 xml에서 활용하며된다.</p><p><strong>Mapper XML</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;insert id=<span class="string">"insert"</span> parameterType=“com.example.table<span class="string">"&gt;</span></span><br><span class="line"><span class="string">      insert into test (id, name, age)</span></span><br><span class="line"><span class="string">    VALUES</span></span><br><span class="line"><span class="string">    &lt;foreach item="</span>table<span class="string">" index="</span>index<span class="string">" collection="</span>list<span class="string">"  separator="</span>,<span class="string">"&gt;</span></span><br><span class="line"><span class="string">     (</span></span><br><span class="line"><span class="string">      #&#123;table.emsid&#125;,</span></span><br><span class="line"><span class="string">      #&#123;table.id&#125;,</span></span><br><span class="line"><span class="string">      #&#123;table.name&#125;,</span></span><br><span class="line"><span class="string">      #&#123;table.age&#125;</span></span><br><span class="line"><span class="string">     )</span></span><br><span class="line"><span class="string">    &lt;/foreach&gt;</span></span><br><span class="line"><span class="string">  &lt;/insert&gt;</span></span><br></pre></td></tr></table></figure><p>foreach 태그에서 collection 컬럼은 넘겨진 파라미터가 List 형태이므로 list라고 적어주면 된다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;30만정도 되는 데이터를 insert 해야하는데 for문을 이용한 단순 반복문으로 실행하니 insert가 안된다.&lt;/p&gt;
&lt;p&gt;그래서 Mapper xml 에서 &lt;foreach&gt; 테그를 이용하여 대량의 데이터를 insert 하는 방법을 적어둔다.&lt;
      
    
    </summary>
    
      <category term="Java" scheme="https://osujin.github.io/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>Java ThreadPool Example</title>
    <link href="https://osujin.github.io/2017/11/13/java-threadpool-example/"/>
    <id>https://osujin.github.io/2017/11/13/java-threadpool-example/</id>
    <published>2017-11-13T00:22:06.000Z</published>
    <updated>2018-04-04T05:55:11.275Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.*;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ObjectTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Future future = <span class="keyword">null</span>;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// ExecutorService 인터페이스 구현객체 Executors 정적메서드를 통해 최대 스레드 개수가 2인 스레드 풀 생성</span></span><br><span class="line">        ExecutorService executorService = Executors.newFixedThreadPool(<span class="number">5</span>);</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            Runnable runnable = <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    <span class="comment">//스레드에게 시킬 작업 내용</span></span><br><span class="line">                    ThreadPoolExecutor threadPoolExecutor = (ThreadPoolExecutor) executorService;</span><br><span class="line"> </span><br><span class="line">                    <span class="keyword">int</span> poolSize = threadPoolExecutor.getPoolSize();<span class="comment">//스레드 풀 사이즈 얻기</span></span><br><span class="line">                    String threadName = Thread.currentThread().getName();<span class="comment">//스레드 풀에 있는 해당 스레드 이름 얻기</span></span><br><span class="line">                    System.out.println(<span class="string">"[총 스레드 개수:"</span> + poolSize + <span class="string">"] 작업 스레드 이름: "</span> + threadName);</span><br><span class="line"> </span><br><span class="line">                    <span class="comment">//일부로 예외 발생 시킴</span></span><br><span class="line"><span class="comment">//                    int value = Integer.parseInt("예외");</span></span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">                        System.out.println(<span class="keyword">new</span> Date().toString());</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line"> </span><br><span class="line">            <span class="comment">//스레드풀에게 작업 처리 요청</span></span><br><span class="line"><span class="comment">//            executorService.execute(runnable);</span></span><br><span class="line">          future = executorService.submit(runnable);</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                future.get();</span><br><span class="line">                System.out.println(<span class="string">"[작업 처리 완료]"</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (ExecutionException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="comment">//스레드풀 종료</span></span><br><span class="line">        executorService.shutdown();</span><br><span class="line">        System.out.println(<span class="string">"Finish"</span>);</span><br><span class="line"> </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=
      
    
    </summary>
    
      <category term="Java" scheme="https://osujin.github.io/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>spring @Value Annotation 사용법</title>
    <link href="https://osujin.github.io/2017/09/20/spring-boot/spring-@Value-Annotation-%EC%82%AC%EC%9A%A9%EB%B2%95/"/>
    <id>https://osujin.github.io/2017/09/20/spring-boot/spring-@Value-Annotation-사용법/</id>
    <published>2017-09-20T02:21:32.000Z</published>
    <updated>2018-08-23T04:51:18.167Z</updated>
    
    <content type="html"><![CDATA[<p>spring을 이용하여 @Value Annotation 사용할때 properties 파일과 mapping 시키는데 삽질한 내용이다.</p><p>SpringContext.xml 에 아래와 같은 내용 properties를 만들어주고 context:component-scan 또한 선언해주어야 @Value Annotation 이 선언된 class 에서 properties를 참조하여 사용할수 있다.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">util:properties</span> <span class="attr">id</span>=<span class="string">"prop"</span> <span class="attr">location</span>=<span class="string">“classpath:sample.properties</span>" /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">“com.spring.test</span>" /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">context:property-placeholder</span> <span class="attr">properties-ref</span>=<span class="string">"prop"</span>  /&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;spring을 이용하여 @Value Annotation 사용할때 properties 파일과 mapping 시키는데 삽질한 내용이다.&lt;/p&gt;
&lt;p&gt;SpringContext.xml 에 아래와 같은 내용 properties를 만들어주고 context:
      
    
    </summary>
    
      <category term="Java" scheme="https://osujin.github.io/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>spring-boot application.yml column mapping 사용 예제</title>
    <link href="https://osujin.github.io/2017/09/20/spring-boot/spring-boot-application.yml-column-mapping-%EC%82%AC%EC%9A%A9-%EC%98%88%EC%A0%9C/"/>
    <id>https://osujin.github.io/2017/09/20/spring-boot/spring-boot-application.yml-column-mapping-사용-예제/</id>
    <published>2017-09-20T02:14:45.000Z</published>
    <updated>2018-04-04T05:58:56.858Z</updated>
    
    <content type="html"><![CDATA[<p>spring-boot 에서 properties 파일을 사용하지 않고 yml 이라는 파일을 사용해 설정값등을 명시해주는데 이에대한 간략한 사용방법이다.</p><p>일단 resource 하위에 application.yml 파일을 만들고 아래와 같이 내용을 채워넣는다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  profiles:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">  datasource:</span></span><br><span class="line"><span class="attr">    url:</span> <span class="attr">jdbc:postgresql://1.1.1.1:5432/abc</span></span><br><span class="line"><span class="attr">    username:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">    password:</span> <span class="string">test123</span></span><br><span class="line"></span><br><span class="line"><span class="attr">settings:</span></span><br><span class="line"><span class="attr">  user:</span></span><br><span class="line"><span class="attr">    id:</span> <span class="string">osujin12</span></span><br><span class="line"><span class="attr">    pw:</span> <span class="string">aaaa</span></span><br><span class="line"><span class="attr">  server:</span></span><br><span class="line"><span class="attr">    ip:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br></pre></td></tr></table></figure><p>그리고 위 내용을 매핑시킬 context class 를 하나 선언하고 Annotation을 선언해주면 자동으로 매핑이 되는데 몇가지 방법이 존재한다.</p><ol><li><p>@Value 를 이용하여 1:1 로 mapping 하는방법</p><ul><li>@Configuration , @EnableConfigurationProperties</li></ul></li></ol><p>위두개의 Annotation을 선언해주면 자동으로 yml 파일을(application.yml 파일은 따로 설정없이 자동으로 인식한다. 이름이 여러개의 yml 파일도 적용할수 있는데 이런경우 추가 설정이 필요하다.) load 한다. 그리고 선언된 변수에 yml 컬럼 명을 명시해주면 값이 셋팅된다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@Value(&quot;$&#123;settings.server.ip&#125;&quot;)</span><br><span class="line">   String ip;</span><br></pre></td></tr></table></figure><ol><li><p>객체에 yml을 mapping 하는 방법</p><ul><li>@ConfigurationProperties(prefix = “settings”)</li></ul></li></ol><p>1번의 Annotation과 함께 위에 선언된 ConfigurationProperties Annotation을 사용하면 settings 하위에 있는 user,server 항목을 객체로 변환하여 자동으로 maaping 할수 있다.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    String id;</span><br><span class="line">    String pw;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setId</span><span class="params">(String id)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getPw</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> pw;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPw</span><span class="params">(String pw)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.pw = pw;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>위와 같이 User 클래스를 선언한뒤 Context에 User 를 선언만 해주면 된다.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableConfigurationProperties</span></span><br><span class="line"><span class="meta">@ConfigurationProperties</span>(prefix = <span class="string">"settings"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Context</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;settings.server.ip&#125;"</span>)</span><br><span class="line">    String ip;</span><br><span class="line"> </span><br><span class="line">    User user; </span><br><span class="line"><span class="comment">//getter , setter 생략 </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Context class 결과</strong></p><p><img src="/image/2017/09/스크린샷-2017-09-20-오전-11.13.25.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;spring-boot 에서 properties 파일을 사용하지 않고 yml 이라는 파일을 사용해 설정값등을 명시해주는데 이에대한 간략한 사용방법이다.&lt;/p&gt;
&lt;p&gt;일단 resource 하위에 application.yml 파일을 만들고 아래와 같이
      
    
    </summary>
    
      <category term="Java" scheme="https://osujin.github.io/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>spring-boot mybatis 연동 주의점</title>
    <link href="https://osujin.github.io/2017/09/07/spring-boot/spring-boot-mybatis-%EC%97%B0%EB%8F%99-%EC%A3%BC%EC%9D%98%EC%A0%90/"/>
    <id>https://osujin.github.io/2017/09/07/spring-boot/spring-boot-mybatis-연동-주의점/</id>
    <published>2017-09-07T06:09:53.000Z</published>
    <updated>2018-04-04T06:01:25.484Z</updated>
    
    <content type="html"><![CDATA[<p>spring boot 를 이용하여 DB를 연동할때 자동으로 DB 커넥션을 생성하는 방법을 사용하는데</p><p>yml 파일에 db 연결 정보를 아래 규격에 맞춰야 한다.</p><p>spring 이라는 element 아래 datasource element를 생성하고 그 하위에 url,username,password 를 입력해주면 자동으로 불러와 셋팅을 해준다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  profiles:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">  datasource:</span></span><br><span class="line"><span class="attr">    url:</span> <span class="attr">jdbc:postgresql://58.181.37.137:5432/tsdn</span></span><br><span class="line"><span class="attr">    username:</span> <span class="string">tsdn</span></span><br><span class="line"><span class="attr">    password:</span> <span class="number">123</span><span class="string">!@#</span></span><br></pre></td></tr></table></figure><p>yml 파일을 설정한 뒤에는 Mapperscan annotation 을 선언해줘야 하는데 sping에 의존성이 주입된 class 어디서나 선언해도 자동으로 불러들이는 것같다.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@MapperScan</span>(“com.java.test.pkg)</span><br></pre></td></tr></table></figure><p>하지만 명시적으로 확인해주기 위해 dao 관련 class에서 선언을 해주는게 좋을것 같다.</p><p>MapperScan을 선언해주지 않으면 sql connection이 자동으로 생성되지 않는다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;spring boot 를 이용하여 DB를 연동할때 자동으로 DB 커넥션을 생성하는 방법을 사용하는데&lt;/p&gt;
&lt;p&gt;yml 파일에 db 연결 정보를 아래 규격에 맞춰야 한다.&lt;/p&gt;
&lt;p&gt;spring 이라는 element 아래 datasource e
      
    
    </summary>
    
      <category term="Java" scheme="https://osujin.github.io/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>Facebook Chatbot 과 Redis 활용</title>
    <link href="https://osujin.github.io/2017/08/28/Facebook-Chatbot%EA%B3%BC-Redis-%ED%99%9C%EC%9A%A9/"/>
    <id>https://osujin.github.io/2017/08/28/Facebook-Chatbot과-Redis-활용/</id>
    <published>2017-08-28T05:17:07.000Z</published>
    <updated>2018-04-04T02:14:12.749Z</updated>
    
    <content type="html"><![CDATA[<p>Node.js로 Facebook Chatboot 서비스를 구축하며 다른 서비스들과 연동을 해야하는데 데이터 저장을 위한 DB로 Redis를 활용해보았다.</p><p>redis는 NoSQL DB로 key-value 구조로 데이터를 저장하는 구조라서 복잡한 서비스에 대한 데이터를 수용하기엔 적절치 않지만 NoSQL DB도 써볼겸 적용해보았다.</p><p>일단 Facebook chatbot에서 사용하는 아이디와 Facebook email 정보를 저장하고 Facebook Chatboot 고유 id 와 email 주소를 매핑 시켜줄 저장소를 DB0 에 저장했다. ( Redis는 기본적으로 16개의 독립적인 DB 구역을 사용할수 있다)</p><p>이는 최초 chatbot을 통해 내가 구현한 서비스와 facebook 계정을 연동 해주기 위한 DB로 활용되었다.</p><p><img src="/image/2017/08/스크린샷-2017-08-28-오전-11.17.52.png" alt=""></p><p>위 그림처럼 account linking 라고 메시지를 보내면 facebook과 MemoryCalendar 서비스를 연동시킬수 있는 url이 넘어오고 이를 클릭하고 facebook login 버튼을 눌러 연동을 하면 MemoryCalendar에서 해당 유저의 정보를 확인 할 수 있다.</p><p>facebook 연동 과정과 Redis에 저장되는 데이터를 함께 확인하면 아래와 같다.</p><ol><li>account linking 매시지 전송 : redis - user 고유 ID를 key값으로하고 랜덤하게 생성된 임이의 문자열을 value로 하여 encryptChatID를 key값으로 하는 저장소에 저장하였다.</li></ol><p><img src="/image/2017/08/스크린샷-2017-08-28-오후-2.01.58.png" alt=""></p><ol><li>url클릭 후 facebook login 버튼 클릭 : facebook login 버튼을 눌러 연동을 하면 개인정보 접근이 가능하고 email 주소와 chat Id 를 맵핑 시켜 idMapper 를 key 로 하는 저장소에 저장하였다.</li></ol><p><img src="/image/2017/08/스크린샷-2017-08-28-오후-2.05.49.png" alt=""></p><p>이와 같은 방법으로 email 주소를 통해 chatId 를 찾을 수 있도록 하였고 chatId 가 외부로 노출되는 경우를 방지하기 위해 임시 key 값을 발급하는 형태로 구조를 잡았다.</p><p>앞으로 서비스에서 사용될 개별 유저 셋팅에 대한 정보도 email 이나 chatid를 이용하여 설계하여 개발하면 된다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Node.js로 Facebook Chatboot 서비스를 구축하며 다른 서비스들과 연동을 해야하는데 데이터 저장을 위한 DB로 Redis를 활용해보았다.&lt;/p&gt;
&lt;p&gt;redis는 NoSQL DB로 key-value 구조로 데이터를 저장하는 구조라
      
    
    </summary>
    
      <category term="IoT" scheme="https://osujin.github.io/categories/IoT/"/>
    
    
  </entry>
  
  <entry>
    <title>gitlab 관리자 비번 초기화 및 project limit 늘리기</title>
    <link href="https://osujin.github.io/2017/07/18/gitlab-%EA%B4%80%EB%A6%AC%EC%9E%90-%EB%B9%84%EB%B2%88-%EC%B4%88%EA%B8%B0%ED%99%94-%EB%B0%8F-project-limit-%EB%8A%98%EB%A6%AC%EA%B8%B0/"/>
    <id>https://osujin.github.io/2017/07/18/gitlab-관리자-비번-초기화-및-project-limit-늘리기/</id>
    <published>2017-07-18T04:46:53.000Z</published>
    <updated>2018-04-04T06:11:34.885Z</updated>
    
    <content type="html"><![CDATA[<p>gitlab 관리자 비번 설정</p><ol><li>gitlab 설치 계정으로 로그인</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$gitlab-rails console production</span><br><span class="line"></span><br><span class="line">irb(main):002:0* user = User.where(id: 1).first</span><br><span class="line"></span><br><span class="line">irb(main):003:0&gt; user.password = ‘secret_pass’</span><br><span class="line"></span><br><span class="line">irb(main):004:0&gt; user.password_confirmation = ‘secret_pass’</span><br><span class="line"></span><br><span class="line">irb(main):005:0&gt; user.save!</span><br></pre></td></tr></table></figure><ol><li>project limit 변경 gitlab 기본 설정시 프로젝트 개수 제한이 10개로 설정되어있는데 이미 계정을 만들고 나서 관리자 계정으로 이 설정을 변경해도 기존에 만들어진 계정에는 적용이 안되었다. 이럴때는 수동으로 값을 변경해주면 된다.</li></ol><ul><li>gitlab 설치 계정으로 로그인</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab-rails console production</span><br><span class="line"></span><br><span class="line">irb(main):002:0* user = User.where(id: [변경하려는 계정의 숫자]).first</span><br><span class="line"></span><br><span class="line">irb(main):003:0&gt; user.projects_limit = 99999</span><br><span class="line"></span><br><span class="line">irb(main):005:0&gt; user.save!</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;gitlab 관리자 비번 설정&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;gitlab 설치 계정으로 로그인&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span clas
      
    
    </summary>
    
      <category term="기타" scheme="https://osujin.github.io/categories/%EA%B8%B0%ED%83%80/"/>
    
    
  </entry>
  
  <entry>
    <title>Facebook Messenger와 Node js 를 이용하여 아두이노 조작하기</title>
    <link href="https://osujin.github.io/2017/07/05/Facebook-Messenger%EC%99%80-Node.js%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC-%EC%95%84%EB%91%90%EC%9D%B4%EB%85%B8-%EC%A1%B0%EC%9E%91%ED%95%98%EA%B8%B0/"/>
    <id>https://osujin.github.io/2017/07/05/Facebook-Messenger와-Node.js를-이용하여-아두이노-조작하기/</id>
    <published>2017-07-05T07:05:23.000Z</published>
    <updated>2018-04-04T06:04:47.767Z</updated>
    
    <content type="html"><![CDATA[<p>페이스북 메신저에서 제공하는 챗봇(chat-bot) 기능을 통해 아두이노와 같은 장비에 메시지를 주고 받는 기능을 개발해보기로 했다.</p><p>가장 먼저 <a href="https://developers.facebook.com/docs/messenger-platform/guides/quick-start" target="_blank" rel="noopener">페이스북 메신저 SDK</a> 사이트를 참고하여 챗봇이 가능한 환경을 셋팅해주고 Node js 로 서비스가 가능한 소스를 개인서버에서 동작시켜줘야한다.</p><p>챗봇 서비스를 정상적으로 실행하기 위해서는 필히 https 를 통해 서비스를 제공하도록 제한하고 있는것 같다.</p><p>그런데 <a href="https://github.com/fbsamples/messenger-platform-samples" target="_blank" rel="noopener">github</a>에 올라온 소스는 https가 완전히 적용된 소스가 아니라 추가적인 수정이 필요하다.</p><p>그리고 app.js 파일에 모든 소스가 있기때문에 이를 분리해줘야 한다. 분리작업은 express router 기능을 이용하면 손쉽게 분리가 된다.</p><p>분리할때 url 경로를 기준으로 분리했는데</p><ol><li>/authorize</li><li>/webhook</li></ol><p>이렇게 두개의 router 를 만들어 분리를 했다.</p><p>url을 분리한뒤에는 TOKEN 관련 상수들도 추가해주어야 페이스북 메신저에서 보낸 메시지가 제대로 날라오게 된다.</p><p>github에 올라온 소스는 app.js 에서 Listener 까지 띄워주지만 나는 Express 를 이용했기 때문에 www 라는 파일에서 Listener를 띄워줘야한다.</p><p>여기서 한가지 큰 문제가 있었다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[FB messenger] &lt;--https--&gt; [개인서버] &lt;--websocket--&gt; [아두이노]</span><br></pre></td></tr></table></figure><p>이렇게 서로 통신프로토콜을 정하였는데 websocket 과 https Listener 둘다 같은 port로 동작하도록 구현을 해야만 했다.</p><p>websocket 도 https 와 마찬가지로 router를 이용하여 서비스 별로 분리를 하려고 <a href="https://www.npmjs.com/package/express-ws-routes" target="_blank" rel="noopener">express-ws-routes</a> 모듈을 이용하여 websocket을 구현했다.</p><p>그런데 이 모듈은 WebSocket Security 를 지원하도록 만들어진건 아니라 일부분 수정이 필요했다.</p><p>일단 www 파일에서 Listener 를 띄우는 부분을 살펴보자</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> options = &#123;</span><br><span class="line">    key: fs.readFileSync(<span class="string">'./keys/privkey.pem'</span>),</span><br><span class="line">    ca : fs.readFileSync(<span class="string">'./keys/chain.pem'</span>),</span><br><span class="line">    cert: fs.readFileSync(<span class="string">'./keys/cert.pem'</span>)</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> server = app.listen(options,app,<span class="number">3000</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'Websocket listening on port 3000...'</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>위소스에서 app.listen으로 넘겨지는 파라미터가 options,app,3000 총 3개인데 original source 에서는 포트 번호만 넘겨주고 끝이었다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">options</span> <span class="string">:</span> <span class="string">인증서</span> <span class="string">파일</span></span><br><span class="line"><span class="string">app</span> <span class="string">:</span> <span class="string">https</span> <span class="string">requestListener(router)</span></span><br><span class="line"><span class="number">3000</span> <span class="string">:</span> <span class="string">port</span> <span class="string">번호</span></span><br></pre></td></tr></table></figure><p>넘겨지는 파라미터는 위와 같은데 인증서 파일과 https requestListener를 동작할 수 있도록 추가적인 파라미터를 넘겨줘야 했고 이에 맞게 express-ws-routes 소스도 약간의 수정이 필요했다.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">exports = <span class="built_in">module</span>.exports = <span class="function"><span class="keyword">function</span>(<span class="params">options</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> app = exports.extendExpress(options)();</span><br><span class="line"></span><br><span class="line">    app.listen = <span class="function"><span class="keyword">function</span>(<span class="params">sslOption,requestListener,port</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> server = https.createServer(sslOption,requestListener);</span><br><span class="line">        server.listen(port)</span><br><span class="line">        server.wsServer = exports.createWebSocketServer(server, app, options);</span><br><span class="line">        <span class="keyword">return</span> server.listen.apply(server);</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> app;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>위 소스가 수정된 소스인데 sslOption,requestListener,port 3개의 파라미터를 받아 https listener를 띄웠고 https 를 이용하여 websocket도 띄웠기 때문에 WebSocket Security 로 서비스가 올라갔다.</p><p>websocket 의 router 기능은 express-ws-routes 모듈내에서 지원해주는 기능이기 때문에 별도록 신경 쓸것은 없다.</p><p>여기 까지 했으면 일단 전체적인 틀은 잡은것이라고 생각한다.</p><p>마지막으로 확인해봐야 할것이 facebook messenger 와 통신과 아두이노와 통신이 되는지 확인해보는것인데 facebook messenger 에서 메시지를 날리면 몇몇 단어를 제외하곤 전부 echo를 하게 되어있다. 제대로 echo가 되는지 확인을 해보면 되고 websocket 통신은 간단한 websocket client를 만들어 접속해보고 접속이 잘되면 문제가 없는것이다.</p><p>마지막으로 여러대의 아두이노 들을 관리하기 위해 socket을 별도로 관리 해주어야 하는데 <a href="https://simplapi.wordpress.com/2012/05/14/node-js-singleton-structure/" target="_blank" rel="noopener">Node.JS Singleton structure</a> 이곳에 있는 소스를 참고하여 singleton 객체를 하나 만들어 socket을 저장하고 fb 메신저에서 특정 단어가 들어가면 singleton 객체에 저장된 소켓리스트에서 해당하는 아두이노를 찾아 메시지를 보내는 형식으로 구현을 하였다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;페이스북 메신저에서 제공하는 챗봇(chat-bot) 기능을 통해 아두이노와 같은 장비에 메시지를 주고 받는 기능을 개발해보기로 했다.&lt;/p&gt;
&lt;p&gt;가장 먼저 &lt;a href=&quot;https://developers.facebook.com/docs/mes
      
    
    </summary>
    
      <category term="IoT" scheme="https://osujin.github.io/categories/IoT/"/>
    
    
  </entry>
  
  <entry>
    <title>Synology NAS에서 예능 자동으로 다운받고 폴더별로 분류하기</title>
    <link href="https://osujin.github.io/2017/06/12/Synology-NAS%EC%97%90%EC%84%9C-%EC%98%88%EB%8A%A5-%EC%9E%90%EB%8F%99%EC%9C%BC%EB%A1%9C-%EB%8B%A4%EC%9A%B4%EB%B0%9B%EA%B3%A0-%ED%8F%B4%EB%8D%94%EB%B3%84%EB%A1%9C-%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0/"/>
    <id>https://osujin.github.io/2017/06/12/Synology-NAS에서-예능-자동으로-다운받고-폴더별로-분류하기/</id>
    <published>2017-06-12T00:41:59.000Z</published>
    <updated>2018-04-23T00:30:34.427Z</updated>
    
    <content type="html"><![CDATA[<p>synology 토렌트 다운로드에 RSS 다운로드 기능이 있다는것은 알았지만 다운받고 또 일일이 수동으로 분류하는것이 번거러워 잘 사용하지는 않았다.</p><p>그런데 파일 자동분류 프로그램을 만들어 다운로드 폴더를 모니터링 하고 있다가 자동으로 해당 폴더로 영상을 옮겨주는 프로그램을 만들면 좋겠다는 생각이 들어 Node JS를 이용해 만들어 보았다.</p><p>먼저 RSS 이용방법은 RooT님의 블로그를 보고 참고하면 된다. <a href="http://blog.iroot.kr/62" target="_blank" rel="noopener">Synology NAS RSS 사용법</a></p><p>RSS를 이용하여 즐겨보는 예능을 자동으로 특정폴더로 다운받도록 예약을 걸어놓고 자동분류 프로그램을 돌리면 예능들이 자동으로 이름에 맞게 폴더로 이동된다.</p><p>Node js를 이용해서 만들다 보니 한글처리에 약간의 문제가 있었는데 파일명을 그대로 사용하지 말고 buffer로 감싸주어 변환시켜주니 한글이 깨지지 않고 그대로 출력되었다.</p><p>파일을 분류하는 방법은 영상에 있는 프로그램 제목과 폴더명을 맞추도록 했는데 파일명에서 . 과 공백으로 파일명을 잘라 일일이 비교를 하는 방법을 사용하였다.</p><p>예를들어 “[tvN] 코미디 빅리그.E170.170521.720p-NEXT.mp4” 이라는 파일이 있을때 이를 split 하면 아래와 같이 분류가 되는데<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[tvN]</span><br><span class="line">코미디</span><br><span class="line">빅리그</span><br><span class="line">E170</span><br><span class="line">170521</span><br><span class="line">720p-NEXT</span><br><span class="line">mp4</span><br></pre></td></tr></table></figure></p><p>node js의 fs 모듈을 이용해 특정 폴더를 모니터링하는 watcher를 만들고 새로운 파일이 감지되면 예능 폴더에 있는 폴더 리스트를 array로 가져와 위 파일명과 폴더명을 비교하여 일치하는 것이 있으면 해당 폴더로 이동시키도록 해보니 큰 문제 없이 정상 동작하였다.</p><p>그리고 damon 으로 뛰우기 위해 forever를 이용하여 기동하였다.</p><p><a href="https://github.com/osujin/AutoClassify.git" target="_blank" rel="noopener">소스코드 github link.</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;synology 토렌트 다운로드에 RSS 다운로드 기능이 있다는것은 알았지만 다운받고 또 일일이 수동으로 분류하는것이 번거러워 잘 사용하지는 않았다.&lt;/p&gt;
&lt;p&gt;그런데 파일 자동분류 프로그램을 만들어 다운로드 폴더를 모니터링 하고 있다가 자동으
      
    
    </summary>
    
      <category term="기타" scheme="https://osujin.github.io/categories/%EA%B8%B0%ED%83%80/"/>
    
    
  </entry>
  
</feed>

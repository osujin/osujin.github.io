{"meta":{"title":null,"subtitle":null,"description":"개인적인 프로젝트와 개발관련 블로그","author":"sujin Oh","url":"https://osujin.github.io"},"pages":[],"posts":[{"title":"Spring-boot JPA 초기 설정방법","slug":"Spring-boot JPA 초기 설정방법 ","date":"2018-08-23T02:00:32.000Z","updated":"2018-08-23T04:34:58.053Z","comments":true,"path":"2018/08/23/Spring-boot JPA 초기 설정방법 /","link":"","permalink":"https://osujin.github.io/2018/08/23/Spring-boot JPA 초기 설정방법 /","excerpt":"","text":"Spring boot 를 이용하여 신규 프로젝트를 진행할 때 JPA를 활용하는 방법에 대해 적어본다. 제일 먼저 프로젝트를 신규로 생성 해주어야 하는데 https://start.spring.io 페이지에서 제공되는 템플릿을 이용하여 maven 프로젝트를 하나 생성해 주었다. 기본 프로젝트를 생성 하였다면 Intellij 에서 제공하는 JPA entity 생성 plugin을 이용하여 DataBase를 연동해주면 된다 1. Intellij 에 DB연동해주기Intellij 오른쪽 사이바 탭에 DataBase 메뉴를 선택해 “+” 버튼을 눌러 사용고자 하는 DB를 연동해주면 된다. 2. project setting에 들어가 Hibernate Module 추가해주기JPA를 사용하기 위한 표준 기술인 Hibernate를 이용한다 프로젝트를 우클릭하고 project setting 메뉴에 들어가 아래 사진과 같이 Hibernate 모듈을 추가해주고 “+” 버튼을 눌러 hibernate.cfg.xml 파일을 하나 생성해준다 정상적으로 생성 되었으면 아래 그림처럼 왼쪽 사이드바 메뉴에 persistence 라는 메뉴가 생기고 이를 눌러보면 추가된 Hibernate module 이 표시된다. 3. Hibernate 와 DB 연동하기아래 그림과 같이 Database를 hibernate와 연동해주어야 하는데 “By Database Schema” 메뉴를 클릭하면 팝업 창으로 Import Database Schema 창이 뜨고 1 번에서 연동해주었던 DB를 choose Data Source에 선택하고 package 에는 DB table을 java 파일로 변환 한다음 저장될 결로를 선택해주면 된다. 그리고 중앙에 위치한 table List에서 내가하고자한 Table을 선택해 주고 OK 버튼을 누르면 설정된 package 경로에 java 파일이 생성된다. 추가적으로 프로젝트 초기 생성시 jdbc 플러그인을 pom에 따로 추가해주지 않았는데 자신이 사용하고자 하는 DB plugin을 pom에 추가해주면 된다. 여기까지가 Spring boot JPA을 활용하기 위한 초기 설정과정이다.","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://osujin.github.io/categories/JAVA/"}],"tags":[]},{"title":"Linux 서버에서 VPN 자동접속 하는방법","slug":"Linux 서버에서 VPN 자동접속 하는방법","date":"2018-06-21T05:18:40.000Z","updated":"2018-06-21T09:01:56.762Z","comments":true,"path":"2018/06/21/Linux 서버에서 VPN 자동접속 하는방법/","link":"","permalink":"https://osujin.github.io/2018/06/21/Linux 서버에서 VPN 자동접속 하는방법/","excerpt":"","text":"Linux 에서 VPN 접속 끊어지면 자동으로 reconnect 하는 스크립트 nmcli 명령어를 사용하였다 123456789101112#!/bin/bashwhile [ \"true\" ]do VPNCON=$(nmcli con show | grep 'VPN' | cut -f1 -d \" \") if [[ $VPNCON != \"VPN\" ]]; then echo \"Disconnected, trying to reconnect...\" (sleep 1s &amp;&amp; nmcli con up uuid 5f359e9f-010e-43ca-a3a0-25787c9b1359) else echo \"Already connected !\" fi sleep 30done","categories":[{"name":"기타","slug":"기타","permalink":"https://osujin.github.io/categories/기타/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://osujin.github.io/tags/Linux/"}]},{"title":"logstash와 kafka 연동시 Multiple Topic 사용하기","slug":"kafka-logstash","date":"2018-06-20T07:52:29.000Z","updated":"2018-06-20T08:53:48.572Z","comments":true,"path":"2018/06/20/kafka-logstash/","link":"","permalink":"https://osujin.github.io/2018/06/20/kafka-logstash/","excerpt":"","text":"ELK 를 구축할때 kafka 로 프로세스별 log 데이터를 밀어넣은 다음 kafka - logstash 를 연동하여 ElasticSearch로 보내도록 구현중이다. logstash 에서 여러개의 kafka Topic 을 처리하는 방법에 대해서 정리한 내용이다 A123 process =&gt; topic : A1 B123 process =&gt; topic : A2 C123 process =&gt; topic : A3 이런식으로 3개의 프로세스의 로그가 각각 다른 토픽에 저장되어있다. ES(ElasticSearch)에는 다음과 같이 저장하려고 한다 12345index : server-log-[@date]- type - A1-log - A2-log - A3-log logstash 에서 여러개의 topic 을 불러오는건 다음과 같다 12345678input &#123; kafka &#123; bootstrap_servers =&gt; &quot;192.168.202.148:9092&quot; topics =&gt; [&quot;topic1&quot;,&quot;topic2&quot;] group_id =&gt; &quot;logstash&quot; consumer_threads =&gt; 2 decorate_events =&gt; true &#125; 위 topic 부분에 리스트([]) 형식으로 불러올 topic 을 넣어주면 된다. 문제는 topic 들을 각각 다른 ES type으로 분류하여 저장하는것이다. topic 이름으로 구분하여 ES에 저장할때 사용되는 type 을 지정하고 싶은데 topic 을 구분할 수 있는 방법이 topic 명 말고는 없다. 그래서 logstash config 파일에 output 부분에서 topic 명으로 분기를 만들어 주기로 했는데… Removal of mapping types &gt;&gt; multiple type 불가 그렇다.. ES 6 버전부터는 index 당 한개의 type 만 생성이 가능하다. 그전에 input - kafka 안쪽에 “decorate_events =&gt; true” 설정을 꼭 넣어주자 그래야 topic 을 불러올수가 있다. type을 여러개 만들면 이와같은 오류가 발생한다. 1Rejecting mapping update to [index1-2018.06.20] as the final mapping would have more than 1 type 공식 문서에는 document_type을 생성하여 기존 type을 대체하라고 했는데 나는 그냥 원본 데이터에 새로 pName 필드를 추가하여 구분하는 방식으로 해보았다 최종 왼성된 config 설정은 아래와 같다 123456789101112131415161718192021222324252627282930313233input &#123; kafka &#123; bootstrap_servers =&gt; &quot;192.168.202.148:9092&quot; topics =&gt; [&quot;topic1&quot;,&quot;topic2&quot;] group_id =&gt; &quot;logstash&quot; consumer_threads =&gt; 2 decorate_events =&gt; true &#125;&#125;filter &#123; if [@metadata][kafka][topic] == &quot;topic1&quot; &#123; mutate &#123; add_field =&gt; &#123;&apos;pName&apos; =&gt; &apos;topic1&apos;&#125; &#125; &#125;if [@metadata][kafka][topic] == &quot;topic2&quot; &#123; mutate &#123; add_field =&gt; &#123;&apos;pName&apos; =&gt; &apos;topic2&apos;&#125; &#125; &#125; json &#123; source =&gt; &quot;message&quot; &#125;&#125;output &#123;elasticsearch &#123; hosts =&gt; [&quot;127.0.0.1:9200&quot;] index =&gt; &quot;index-%&#123;+YYYY.MM.dd&#125;&quot; document_type =&gt; &quot;logs&quot; &#125;&#125; if [@metadata][kafka][topic] 를 이용하여 topic 을 불러와 새로운 필드를 추가하는 방식으로 프로세스별 로그를 구분하도록 하였다.","categories":[{"name":"기타","slug":"기타","permalink":"https://osujin.github.io/categories/기타/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://osujin.github.io/tags/kafka/"},{"name":"logstash","slug":"logstash","permalink":"https://osujin.github.io/tags/logstash/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://osujin.github.io/tags/ElasticSearch/"}]},{"title":"MemoryCalendar_V1","slug":"MemoryCalendar-V1","date":"2018-04-20T07:05:23.000Z","updated":"2018-04-20T05:56:17.369Z","comments":true,"path":"2018/04/20/MemoryCalendar-V1/","link":"","permalink":"https://osujin.github.io/2018/04/20/MemoryCalendar-V1/","excerpt":"","text":"대학교 재학 시절 졸업작품으로 만들었던 MemoryCalendar 라는 제품의 V2 버전을 제작하기전에 초기 버전에 대한 간단한 리뷰를 작성하려고 한다. 제품 개발 컨센은 다음과 같았다. 흔히 사용하는 탁상달력에 LED 모듈을 달아 자체제작한 스마트폰 달력 App과 연동하여 LED를 제어하고자 하는것이 가장 큰 목표였다. 추가적으로 LCD 모둘과의 페이스북 계정을 연동하여 과거의 오늘 사진을 LCD로 보여주는 액자기능도 제공하였다. 프로젝트 구성도 각 모듈을 구성하는 핵심요소Server- Arduino와 서버의 지속적인 연결을 위해 Websocket(Node.js)을 사용하여 동기화. - redis를 사용하여 빠른 데이터 접근 → 실시간으로 데이터를 주고받음. - WebSocket 헤더에 User_ID와 Client type을 추가하여 서버에서 구분. - Python으로 구현한 구글 검색 기반의 Crawler를 통한 관심사 이미지 검색. Arduino(달력)- Websocket을 이용하여 서버와 통신. - App에서 설정한 LED정보를 받음. - JSON array parsing을 통해 LED 데이터 추출 Raspberry pi(액자)- Websocket(Node.js)을 이용하여 서버와 통신하고 image url 수신. - Node.js를 이용하여 image를 다운로드. - Linux fbi 기능을 통해 image를 Display. Android- Facebook API를 이용한 자동 로그인과 과거 데이터 추출. - Picasso 라이브러리를 사용하여 실시간 이미지 로딩. - Websocket을 이용하여 서버와 통신. - 등록된 일정, LED정보, 관심사 설정 값들을 서버로 송신 및 동기화. 최종적으로 왼성된 제품은 아래와 같다. 마지막으로 최종 제작된 제품설명 동영상을 첨부한다.","categories":[{"name":"MemoryCalendar","slug":"MemoryCalendar","permalink":"https://osujin.github.io/categories/MemoryCalendar/"}],"tags":[]},{"title":"mybatis foreach를 이용해 insert batch 처리하기","slug":"mybatis-foreach를-이용해-insert-batch-처리하기","date":"2018-01-16T08:46:22.000Z","updated":"2018-04-04T05:56:15.855Z","comments":true,"path":"2018/01/16/mybatis-foreach를-이용해-insert-batch-처리하기/","link":"","permalink":"https://osujin.github.io/2018/01/16/mybatis-foreach를-이용해-insert-batch-처리하기/","excerpt":"","text":"30만정도 되는 데이터를 insert 해야하는데 for문을 이용한 단순 반복문으로 실행하니 insert가 안된다. 그래서 Mapper xml 에서 테그를 이용하여 대량의 데이터를 insert 하는 방법을 적어둔다. java code 12345678910SqlSession sqlSession = null; List&lt;table&gt; tableList; try &#123; sqlSession = getSqlSessionFactory().openSession(false); Mapper table = sqlSession.getMapper(Mapper.class); Mapper.insert(tableList);//List를 넘겨준다. &#125; finally &#123; sqlSession.commit(); &#125; 위와 같이 List를 Mapper로 전달해주고 xml에서 활용하며된다. Mapper XML 123456789101112&lt;insert id=\"insert\" parameterType=“com.example.table\"&gt; insert into test (id, name, age) VALUES &lt;foreach item=\"table\" index=\"index\" collection=\"list\" separator=\",\"&gt; ( #&#123;table.emsid&#125;, #&#123;table.id&#125;, #&#123;table.name&#125;, #&#123;table.age&#125; ) &lt;/foreach&gt; &lt;/insert&gt; foreach 태그에서 collection 컬럼은 넘겨진 파라미터가 List 형태이므로 list라고 적어주면 된다.","categories":[{"name":"Java","slug":"Java","permalink":"https://osujin.github.io/categories/Java/"}],"tags":[]},{"title":"Java ThreadPool Example","slug":"java-threadpool-example","date":"2017-11-13T00:22:06.000Z","updated":"2018-04-04T05:55:11.275Z","comments":true,"path":"2017/11/13/java-threadpool-example/","link":"","permalink":"https://osujin.github.io/2017/11/13/java-threadpool-example/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.util.Date;import java.util.concurrent.*; public class ObjectTest &#123; public static void main(String[] args) &#123; Future future = null; // ExecutorService 인터페이스 구현객체 Executors 정적메서드를 통해 최대 스레드 개수가 2인 스레드 풀 생성 ExecutorService executorService = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 10; i++) &#123; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; //스레드에게 시킬 작업 내용 ThreadPoolExecutor threadPoolExecutor = (ThreadPoolExecutor) executorService; int poolSize = threadPoolExecutor.getPoolSize();//스레드 풀 사이즈 얻기 String threadName = Thread.currentThread().getName();//스레드 풀에 있는 해당 스레드 이름 얻기 System.out.println(\"[총 스레드 개수:\" + poolSize + \"] 작업 스레드 이름: \" + threadName); //일부로 예외 발생 시킴// int value = Integer.parseInt(\"예외\"); try &#123; Thread.sleep(5000); System.out.println(new Date().toString()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; //스레드풀에게 작업 처리 요청// executorService.execute(runnable); future = executorService.submit(runnable); &#125; try &#123; future.get(); System.out.println(\"[작업 처리 완료]\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; //스레드풀 종료 executorService.shutdown(); System.out.println(\"Finish\"); &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://osujin.github.io/categories/Java/"}],"tags":[]},{"title":"spring @Value Annotation 사용법","slug":"spring-@Value-Annotation-사용법","date":"2017-09-20T02:21:32.000Z","updated":"2018-04-04T05:54:35.119Z","comments":true,"path":"2017/09/20/spring-@Value-Annotation-사용법/","link":"","permalink":"https://osujin.github.io/2017/09/20/spring-@Value-Annotation-사용법/","excerpt":"","text":"spring을 이용하여 @Value Annotation 사용할때 properties 파일과 mapping 시키는데 삽질한 내용이다. SpringContext.xml 에 아래와 같은 내용 properties를 만들어주고 context:component-scan 또한 선언해주어야 @Value Annotation 이 선언된 class 에서 properties를 참조하여 사용할수 있다. 12345&lt;util:properties id=\"prop\" location=“classpath:sample.properties\" /&gt;&lt;context:component-scan base-package=“com.spring.test\" /&gt;&lt;context:property-placeholder properties-ref=\"prop\" /&gt;","categories":[{"name":"Java","slug":"Java","permalink":"https://osujin.github.io/categories/Java/"}],"tags":[]},{"title":"spring-boot application.yml column mapping 사용 예제","slug":"spring-boot-application.yml-column-mapping-사용-예제","date":"2017-09-20T02:14:45.000Z","updated":"2018-04-04T05:58:56.858Z","comments":true,"path":"2017/09/20/spring-boot-application.yml-column-mapping-사용-예제/","link":"","permalink":"https://osujin.github.io/2017/09/20/spring-boot-application.yml-column-mapping-사용-예제/","excerpt":"","text":"spring-boot 에서 properties 파일을 사용하지 않고 yml 이라는 파일을 사용해 설정값등을 명시해주는데 이에대한 간략한 사용방법이다. 일단 resource 하위에 application.yml 파일을 만들고 아래와 같이 내용을 채워넣는다. 12345678910111213spring: profiles: dev datasource: url: jdbc:postgresql://1.1.1.1:5432/abc username: test password: test123settings: user: id: osujin12 pw: aaaa server: ip: 127.0.0.1 그리고 위 내용을 매핑시킬 context class 를 하나 선언하고 Annotation을 선언해주면 자동으로 매핑이 되는데 몇가지 방법이 존재한다. @Value 를 이용하여 1:1 로 mapping 하는방법 @Configuration , @EnableConfigurationProperties 위두개의 Annotation을 선언해주면 자동으로 yml 파일을(application.yml 파일은 따로 설정없이 자동으로 인식한다. 이름이 여러개의 yml 파일도 적용할수 있는데 이런경우 추가 설정이 필요하다.) load 한다. 그리고 선언된 변수에 yml 컬럼 명을 명시해주면 값이 셋팅된다. 12@Value(&quot;$&#123;settings.server.ip&#125;&quot;) String ip; 객체에 yml을 mapping 하는 방법 @ConfigurationProperties(prefix = “settings”) 1번의 Annotation과 함께 위에 선언된 ConfigurationProperties Annotation을 사용하면 settings 하위에 있는 user,server 항목을 객체로 변환하여 자동으로 maaping 할수 있다. 1234567891011121314151617181920 public class User &#123; String id; String pw; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getPw() &#123; return pw; &#125; public void setPw(String pw) &#123; this.pw = pw; &#125;&#125; 위와 같이 User 클래스를 선언한뒤 Context에 User 를 선언만 해주면 된다. 12345678910@Configuration@EnableConfigurationProperties@ConfigurationProperties(prefix = \"settings\")public class Context &#123; @Value(\"$&#123;settings.server.ip&#125;\") String ip; User user; //getter , setter 생략 &#125; Context class 결과","categories":[{"name":"Java","slug":"Java","permalink":"https://osujin.github.io/categories/Java/"}],"tags":[]},{"title":"spring-boot mybatis 연동 주의점","slug":"spring-boot-mybatis-연동-주의점","date":"2017-09-07T06:09:53.000Z","updated":"2018-04-04T06:01:25.484Z","comments":true,"path":"2017/09/07/spring-boot-mybatis-연동-주의점/","link":"","permalink":"https://osujin.github.io/2017/09/07/spring-boot-mybatis-연동-주의점/","excerpt":"","text":"spring boot 를 이용하여 DB를 연동할때 자동으로 DB 커넥션을 생성하는 방법을 사용하는데 yml 파일에 db 연결 정보를 아래 규격에 맞춰야 한다. spring 이라는 element 아래 datasource element를 생성하고 그 하위에 url,username,password 를 입력해주면 자동으로 불러와 셋팅을 해준다. 123456spring: profiles: dev datasource: url: jdbc:postgresql://58.181.37.137:5432/tsdn username: tsdn password: 123!@# yml 파일을 설정한 뒤에는 Mapperscan annotation 을 선언해줘야 하는데 sping에 의존성이 주입된 class 어디서나 선언해도 자동으로 불러들이는 것같다. 1@MapperScan(“com.java.test.pkg) 하지만 명시적으로 확인해주기 위해 dao 관련 class에서 선언을 해주는게 좋을것 같다. MapperScan을 선언해주지 않으면 sql connection이 자동으로 생성되지 않는다.","categories":[{"name":"Java","slug":"Java","permalink":"https://osujin.github.io/categories/Java/"}],"tags":[]},{"title":"Facebook Chatbot 과 Redis 활용","slug":"Facebook-Chatbot과-Redis-활용","date":"2017-08-28T05:17:07.000Z","updated":"2018-04-04T02:14:12.749Z","comments":true,"path":"2017/08/28/Facebook-Chatbot과-Redis-활용/","link":"","permalink":"https://osujin.github.io/2017/08/28/Facebook-Chatbot과-Redis-활용/","excerpt":"","text":"Node.js로 Facebook Chatboot 서비스를 구축하며 다른 서비스들과 연동을 해야하는데 데이터 저장을 위한 DB로 Redis를 활용해보았다. redis는 NoSQL DB로 key-value 구조로 데이터를 저장하는 구조라서 복잡한 서비스에 대한 데이터를 수용하기엔 적절치 않지만 NoSQL DB도 써볼겸 적용해보았다. 일단 Facebook chatbot에서 사용하는 아이디와 Facebook email 정보를 저장하고 Facebook Chatboot 고유 id 와 email 주소를 매핑 시켜줄 저장소를 DB0 에 저장했다. ( Redis는 기본적으로 16개의 독립적인 DB 구역을 사용할수 있다) 이는 최초 chatbot을 통해 내가 구현한 서비스와 facebook 계정을 연동 해주기 위한 DB로 활용되었다. 위 그림처럼 account linking 라고 메시지를 보내면 facebook과 MemoryCalendar 서비스를 연동시킬수 있는 url이 넘어오고 이를 클릭하고 facebook login 버튼을 눌러 연동을 하면 MemoryCalendar에서 해당 유저의 정보를 확인 할 수 있다. facebook 연동 과정과 Redis에 저장되는 데이터를 함께 확인하면 아래와 같다. account linking 매시지 전송 : redis - user 고유 ID를 key값으로하고 랜덤하게 생성된 임이의 문자열을 value로 하여 encryptChatID를 key값으로 하는 저장소에 저장하였다. url클릭 후 facebook login 버튼 클릭 : facebook login 버튼을 눌러 연동을 하면 개인정보 접근이 가능하고 email 주소와 chat Id 를 맵핑 시켜 idMapper 를 key 로 하는 저장소에 저장하였다. 이와 같은 방법으로 email 주소를 통해 chatId 를 찾을 수 있도록 하였고 chatId 가 외부로 노출되는 경우를 방지하기 위해 임시 key 값을 발급하는 형태로 구조를 잡았다. 앞으로 서비스에서 사용될 개별 유저 셋팅에 대한 정보도 email 이나 chatid를 이용하여 설계하여 개발하면 된다.","categories":[{"name":"IoT","slug":"IoT","permalink":"https://osujin.github.io/categories/IoT/"}],"tags":[]},{"title":"gitlab 관리자 비번 초기화 및 project limit 늘리기","slug":"gitlab-관리자-비번-초기화-및-project-limit-늘리기","date":"2017-07-18T04:46:53.000Z","updated":"2018-04-04T06:11:34.885Z","comments":true,"path":"2017/07/18/gitlab-관리자-비번-초기화-및-project-limit-늘리기/","link":"","permalink":"https://osujin.github.io/2017/07/18/gitlab-관리자-비번-초기화-및-project-limit-늘리기/","excerpt":"","text":"gitlab 관리자 비번 설정 gitlab 설치 계정으로 로그인 123456789$gitlab-rails console productionirb(main):002:0* user = User.where(id: 1).firstirb(main):003:0&gt; user.password = ‘secret_pass’irb(main):004:0&gt; user.password_confirmation = ‘secret_pass’irb(main):005:0&gt; user.save! project limit 변경 gitlab 기본 설정시 프로젝트 개수 제한이 10개로 설정되어있는데 이미 계정을 만들고 나서 관리자 계정으로 이 설정을 변경해도 기존에 만들어진 계정에는 적용이 안되었다. 이럴때는 수동으로 값을 변경해주면 된다. gitlab 설치 계정으로 로그인 1234567$ gitlab-rails console productionirb(main):002:0* user = User.where(id: [변경하려는 계정의 숫자]).firstirb(main):003:0&gt; user.projects_limit = 99999irb(main):005:0&gt; user.save!","categories":[{"name":"기타","slug":"기타","permalink":"https://osujin.github.io/categories/기타/"}],"tags":[]},{"title":"Facebook Messenger와 Node js 를 이용하여 아두이노 조작하기","slug":"Facebook-Messenger와-Node.js를-이용하여-아두이노-조작하기","date":"2017-07-05T07:05:23.000Z","updated":"2018-04-04T06:04:47.767Z","comments":true,"path":"2017/07/05/Facebook-Messenger와-Node.js를-이용하여-아두이노-조작하기/","link":"","permalink":"https://osujin.github.io/2017/07/05/Facebook-Messenger와-Node.js를-이용하여-아두이노-조작하기/","excerpt":"","text":"페이스북 메신저에서 제공하는 챗봇(chat-bot) 기능을 통해 아두이노와 같은 장비에 메시지를 주고 받는 기능을 개발해보기로 했다. 가장 먼저 페이스북 메신저 SDK 사이트를 참고하여 챗봇이 가능한 환경을 셋팅해주고 Node js 로 서비스가 가능한 소스를 개인서버에서 동작시켜줘야한다. 챗봇 서비스를 정상적으로 실행하기 위해서는 필히 https 를 통해 서비스를 제공하도록 제한하고 있는것 같다. 그런데 github에 올라온 소스는 https가 완전히 적용된 소스가 아니라 추가적인 수정이 필요하다. 그리고 app.js 파일에 모든 소스가 있기때문에 이를 분리해줘야 한다. 분리작업은 express router 기능을 이용하면 손쉽게 분리가 된다. 분리할때 url 경로를 기준으로 분리했는데 /authorize /webhook 이렇게 두개의 router 를 만들어 분리를 했다. url을 분리한뒤에는 TOKEN 관련 상수들도 추가해주어야 페이스북 메신저에서 보낸 메시지가 제대로 날라오게 된다. github에 올라온 소스는 app.js 에서 Listener 까지 띄워주지만 나는 Express 를 이용했기 때문에 www 라는 파일에서 Listener를 띄워줘야한다. 여기서 한가지 큰 문제가 있었다. 1[FB messenger] &lt;--https--&gt; [개인서버] &lt;--websocket--&gt; [아두이노] 이렇게 서로 통신프로토콜을 정하였는데 websocket 과 https Listener 둘다 같은 port로 동작하도록 구현을 해야만 했다. websocket 도 https 와 마찬가지로 router를 이용하여 서비스 별로 분리를 하려고 express-ws-routes 모듈을 이용하여 websocket을 구현했다. 그런데 이 모듈은 WebSocket Security 를 지원하도록 만들어진건 아니라 일부분 수정이 필요했다. 일단 www 파일에서 Listener 를 띄우는 부분을 살펴보자 12345678910var options = &#123; key: fs.readFileSync('./keys/privkey.pem'), ca : fs.readFileSync('./keys/chain.pem'), cert: fs.readFileSync('./keys/cert.pem')&#125;;var server = app.listen(options,app,3000, function() &#123; console.log('Websocket listening on port 3000...');&#125;); 위소스에서 app.listen으로 넘겨지는 파라미터가 options,app,3000 총 3개인데 original source 에서는 포트 번호만 넘겨주고 끝이었다. 123options : 인증서 파일app : https requestListener(router)3000 : port 번호 넘겨지는 파라미터는 위와 같은데 인증서 파일과 https requestListener를 동작할 수 있도록 추가적인 파라미터를 넘겨줘야 했고 이에 맞게 express-ws-routes 소스도 약간의 수정이 필요했다. 123456789101112exports = module.exports = function(options) &#123; var app = exports.extendExpress(options)(); app.listen = function(sslOption,requestListener,port) &#123; var server = https.createServer(sslOption,requestListener); server.listen(port) server.wsServer = exports.createWebSocketServer(server, app, options); return server.listen.apply(server); &#125;; return app;&#125;; 위 소스가 수정된 소스인데 sslOption,requestListener,port 3개의 파라미터를 받아 https listener를 띄웠고 https 를 이용하여 websocket도 띄웠기 때문에 WebSocket Security 로 서비스가 올라갔다. websocket 의 router 기능은 express-ws-routes 모듈내에서 지원해주는 기능이기 때문에 별도록 신경 쓸것은 없다. 여기 까지 했으면 일단 전체적인 틀은 잡은것이라고 생각한다. 마지막으로 확인해봐야 할것이 facebook messenger 와 통신과 아두이노와 통신이 되는지 확인해보는것인데 facebook messenger 에서 메시지를 날리면 몇몇 단어를 제외하곤 전부 echo를 하게 되어있다. 제대로 echo가 되는지 확인을 해보면 되고 websocket 통신은 간단한 websocket client를 만들어 접속해보고 접속이 잘되면 문제가 없는것이다. 마지막으로 여러대의 아두이노 들을 관리하기 위해 socket을 별도로 관리 해주어야 하는데 Node.JS Singleton structure 이곳에 있는 소스를 참고하여 singleton 객체를 하나 만들어 socket을 저장하고 fb 메신저에서 특정 단어가 들어가면 singleton 객체에 저장된 소켓리스트에서 해당하는 아두이노를 찾아 메시지를 보내는 형식으로 구현을 하였다.","categories":[{"name":"IoT","slug":"IoT","permalink":"https://osujin.github.io/categories/IoT/"}],"tags":[]},{"title":"Synology NAS에서 예능 자동으로 다운받고 폴더별로 분류하기","slug":"Synology-NAS에서-예능-자동으로-다운받고-폴더별로-분류하기","date":"2017-06-12T00:41:59.000Z","updated":"2018-04-23T00:30:34.427Z","comments":true,"path":"2017/06/12/Synology-NAS에서-예능-자동으로-다운받고-폴더별로-분류하기/","link":"","permalink":"https://osujin.github.io/2017/06/12/Synology-NAS에서-예능-자동으로-다운받고-폴더별로-분류하기/","excerpt":"","text":"synology 토렌트 다운로드에 RSS 다운로드 기능이 있다는것은 알았지만 다운받고 또 일일이 수동으로 분류하는것이 번거러워 잘 사용하지는 않았다. 그런데 파일 자동분류 프로그램을 만들어 다운로드 폴더를 모니터링 하고 있다가 자동으로 해당 폴더로 영상을 옮겨주는 프로그램을 만들면 좋겠다는 생각이 들어 Node JS를 이용해 만들어 보았다. 먼저 RSS 이용방법은 RooT님의 블로그를 보고 참고하면 된다. Synology NAS RSS 사용법 RSS를 이용하여 즐겨보는 예능을 자동으로 특정폴더로 다운받도록 예약을 걸어놓고 자동분류 프로그램을 돌리면 예능들이 자동으로 이름에 맞게 폴더로 이동된다. Node js를 이용해서 만들다 보니 한글처리에 약간의 문제가 있었는데 파일명을 그대로 사용하지 말고 buffer로 감싸주어 변환시켜주니 한글이 깨지지 않고 그대로 출력되었다. 파일을 분류하는 방법은 영상에 있는 프로그램 제목과 폴더명을 맞추도록 했는데 파일명에서 . 과 공백으로 파일명을 잘라 일일이 비교를 하는 방법을 사용하였다. 예를들어 “[tvN] 코미디 빅리그.E170.170521.720p-NEXT.mp4” 이라는 파일이 있을때 이를 split 하면 아래와 같이 분류가 되는데1234567[tvN]코미디빅리그E170170521720p-NEXTmp4 node js의 fs 모듈을 이용해 특정 폴더를 모니터링하는 watcher를 만들고 새로운 파일이 감지되면 예능 폴더에 있는 폴더 리스트를 array로 가져와 위 파일명과 폴더명을 비교하여 일치하는 것이 있으면 해당 폴더로 이동시키도록 해보니 큰 문제 없이 정상 동작하였다. 그리고 damon 으로 뛰우기 위해 forever를 이용하여 기동하였다. 소스코드 github link.","categories":[{"name":"기타","slug":"기타","permalink":"https://osujin.github.io/categories/기타/"}],"tags":[]},{"title":"HttpsURLConnection을 이용한 통신시 SSL 인증서 수동으로 지정하는 방법","slug":"HttpsURLConnection을-이용한-통신시-SSL-인증서-수동으로-지정하는-방법","date":"2017-06-09T00:58:27.000Z","updated":"2018-04-04T06:13:14.043Z","comments":true,"path":"2017/06/09/HttpsURLConnection을-이용한-통신시-SSL-인증서-수동으로-지정하는-방법/","link":"","permalink":"https://osujin.github.io/2017/06/09/HttpsURLConnection을-이용한-통신시-SSL-인증서-수동으로-지정하는-방법/","excerpt":"","text":"Https를 이용하여 데이터를 주고 받을때 SSL 인증을 해야한다. 기본적으로 1234System.setProperty(\"javax.net.ssl.keyStore\",context.getKeyFile().getAbsolutePath());System.setProperty(\"javax.net.ssl.keyStorePassword\", context.getKeyFilePassword());System.setProperty(\"javax.net.ssl.keyStoreType\", \"PKCS12\");System.setProperty(\"http.keepAlive\",\"false”); 이런식으로 System property를 추가해주면 HttpsURLConnection을 생성할때 자동으로 SSL인증서를 포함 시키지만 간혹 이방법이 안되는 경우가 있다. 이럴때는 수동으로 SSLContext에 keystore를 등록해주면 해결이 된다. 12345678910111213141516171819202122KeyStore clientStore = KeyStore.getInstance(\"PKCS12\");clientStore.load(new FileInputStream(\"test.p12\"), \"testPass\".toCharArray()); KeyManagerFactory kmf = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());kmf.init(clientStore, \"testPass\".toCharArray());KeyManager[] kms = kmf.getKeyManagers(); KeyStore trustStore = KeyStore.getInstance(\"JKS\");trustStore.load(new FileInputStream(System.getProperty(\"java.home\") + \"/lib/security/cacerts\"), \"changeit\".toCharArray()); TrustManagerFactory tmf = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm());tmf.init(trustStore);TrustManager[] tms = tmf.getTrustManagers(); SSLContext sslContext = null;sslContext = SSLContext.getInstance(\"TLS\");sslContext.init(kms, tms, new SecureRandom()); HttpsURLConnection.setDefaultSSLSocketFactory(sslContext.getSocketFactory());URL url = new URL(\"https://www.testurl.com\"); HttpsURLConnection urlConn = (HttpsURLConnection) url.openConnection();","categories":[{"name":"기타","slug":"기타","permalink":"https://osujin.github.io/categories/기타/"}],"tags":[]},{"title":"java8 Default method","slug":"java8-default-method","date":"2017-06-01T01:16:53.000Z","updated":"2018-04-04T05:59:56.984Z","comments":true,"path":"2017/06/01/java8-default-method/","link":"","permalink":"https://osujin.github.io/2017/06/01/java8-default-method/","excerpt":"","text":"자바8에서 새로 추가된 Default method는 기존에 만들어진 interface를 implement 받는 class들에 영향을 주지 않고 interface에 새로운 항목을 추가할 수 있다. 기존에는 이미 생성된 interface에 새로운 method를 추가하려면 이를 implement 받는 모든 class들에도 Override를 해주어야 됬지만 Default method는 interface에 선언 할때에 body도 함께 만들어야 하므로 기본적으로 inerface에서 제공하는 것이다. 123456789101112131415161718192021222324public static void main(String...args)&#123; new D().hello(); &#125; static interface A&#123; public default void hello()&#123; System.out.println(\"Hello from A\"); &#125; public void world(); &#125; static interface B extends A &#123; &#125; static interface C extends A &#123; &#125; static class D implements B, C &#123; @Override public void world() &#123; &#125; &#125; 위 코드에서 public default void hello() 이부분이 Default method를 구현한것이다. 꼭 body를 함께 생성해주어야 한다. body를 생성하지 않으면 error가 발생한다. 그리고 Default method 는 기존 interface와 마찬가지로 override 받을 수 있는데 override를 하여 새롭게 body를 구성하여 기존 interface 처럼 사용가능하다. 또한 interface는 여러개를 implement 받는것이 가능하므로 그동안 지원하지 않았던 다중상속의 기능을 Default method를 이용하여 사용 할 수 있다.","categories":[{"name":"Java","slug":"Java","permalink":"https://osujin.github.io/categories/Java/"}],"tags":[]},{"title":"Java 8 병렬처리와 성능에 대해서","slug":"Java-8-병렬처리와-성능에-대해서","date":"2017-05-31T06:10:01.000Z","updated":"2018-04-04T05:53:27.749Z","comments":true,"path":"2017/05/31/Java-8-병렬처리와-성능에-대해서/","link":"","permalink":"https://osujin.github.io/2017/05/31/Java-8-병렬처리와-성능에-대해서/","excerpt":"","text":"자바 8의 Stream API에서 사용가능한 병렬처리 함수인 parallel를 이용할때 확인해야 할 점이 있다. 1부터 n 까지 더하는 작업을 단순 반복문 , Stream parallel 를 이용한 코드의 동작 시간을 확인해보자. 123456789101112131415//1. 단순 반복문 public static long iterativeSum(long n) &#123; long result = 0; for (long i = 0; i &lt;= n; i++) &#123; result += i; &#125; return result; &#125; //2. Parallel 를 이용하여 병령처리한 작업 public static long parallelSum(long n) &#123; return Stream.iterate(1L, i -&gt; i + 1).limit(n).parallel().reduce(Long::sum).get(); &#125; //출처 Java 8 in Action 결과1231. Iterative Sum done in: 3 msecs 2. Parallel forkJoinSum done in: 95 msecs 3개의 메소드를 실행 해보면 1번이 가장빠르다는것을 확인 할 수 있는데 이 예제에서 iterate 연산은 본질적으로 순차적으로 일어나기 때문에 병령처리를 해도 큰 효과를 보기 힘들고 Steam을 이용하여 계산을 할때는 기본형 데이터 타입이 아닌 참조형으로 변환하는 과정이 있기때문에 더 많은 리소스가 사용된다. 자바8을 공부하며 기존 소스를 자바8로 리펙토링 하려 했는데 무턱대고 적용하기전 확인이 필요하다. Parallel를 이용한 코드의 성능을 높이기 위해선 기본형 long 을 직접 사용하는 “LongStream.rangeClosed“ 를 이용하면 성능을 높일수 있다. 123public static long parallelRangedSum(long n) &#123; return LongStream.rangeClosed(1, n).parallel().reduce(Long::sum).getAsLong(); &#125; 하지만 위 코드도 단순 반복문보다 빠르다고 장담 할 수는 없는데 이는 멀티코어간 데이터교환시 발생하는 비용때문이다. 코어간의 데이터 이동은 큰 작업이고 병렬처리를 할때에 코어간 데이터 교환보다 오래걸리는 작업을 병령처리로 나누어 작업하는게 효율적이다.","categories":[{"name":"Java","slug":"Java","permalink":"https://osujin.github.io/categories/Java/"}],"tags":[]},{"title":"Intel Edison firmware Update 실패시 후속 조치방법","slug":"Intel-Edison-firmware-Update-실패시-후속-조치방법","date":"2017-04-11T02:39:25.000Z","updated":"2018-04-04T02:06:47.310Z","comments":true,"path":"2017/04/11/Intel-Edison-firmware-Update-실패시-후속-조치방법/","link":"","permalink":"https://osujin.github.io/2017/04/11/Intel-Edison-firmware-Update-실패시-후속-조치방법/","excerpt":"","text":"Intel Edison 펌웨어를 업데이트하다 리눅스 커널이 망가져 반쪽의 기능밖에 못하는 상황이 되었다. usb 연결로 boot img를 업로드하려해도 인식 조차안되는 상황.. 그래서 아예 새로운 커널로 새로 로드를 한뒤 다시 펌웨어 업데이트를 하니 정상적으로 업데이트가 진행 되었다. intel edison 공식 메뉴얼에서 약간 수정을 하면 되는데 Flashing the firmware on a system with Mac OS X (manual process) 위 사이트에서 Yocto* complete image 파일 대신 ubilinux.tar.gz 이 파일을 다운받아 압축을 풀고 flashall.sh 를 실행하면 된다. 쉘을 실행한뒤에 “Please plug and reboot the board” 이라는 문구가 나올때 edison board를 맥과 연결해줘야 접속이 된다. 새로운 boot loader가 업로드 되고 sucess가 뜨면 연결을 해지한뒤 Intel_Edison_Setup_Mac_v2016.2.013 을 다운받아 최신 버전의 yocto linux 를 설치해주면 된다.","categories":[{"name":"IoT","slug":"IoT","permalink":"https://osujin.github.io/categories/IoT/"}],"tags":[]},{"title":"iftop 소스 설치","slug":"iftop-소스-설치","date":"2017-04-04T02:06:52.000Z","updated":"2018-04-04T06:10:06.601Z","comments":true,"path":"2017/04/04/iftop-소스-설치/","link":"","permalink":"https://osujin.github.io/2017/04/04/iftop-소스-설치/","excerpt":"","text":"인터넷이 안되는 내부망에서 iftop을 설치가 필요할때 소스 설치를 하는 방법이다. 설치 환경은 centos 6.8 64bit 에서 진행하였다. 필요한 파일은 iftop-0.17.tar.gz libpcap-1.7.4.tar 이고 root 권한으로 설치를 진행한다. 설치파일 : iftop-0.17.tar Download , libpcap-1.7.4 Download 일단 libpcap-1.7.4.tar 파일을 먼저 설치해서 pcap 라이브러리를 설치해줘야 한다. libpcap 라이브러리를 설치할때 flex , bison 이 필요하다고 에러가 나오는데 메뉴얼에 이 두개는 제외하고 설치하는 방법이 나와있다. libpcap 설치방법 12345# tar xf libpcap-1.7.4.tar# cd libpcap-1.7.4# ./configure --without-flex --without-bison# make# make install iftop 설치 방법 123# tar xf iftop-0.17.tar.gz# cd iftop-0.17# ./configure &amp;&amp; make 추가적으로 최근에 개발된 iftop 1.0 버전을 설치하는 방법이다. 1&#46;0 정식 버전은 없고 현재 pre4 버전이 최신 버전인데 이버전을 설치하려면 ncurses 가 필요하다. 설치파일 : ncurses-6.0.tar Download , iftop-1.0pre4.tar Download ncurses 설치방법 1234# tar xf ncurses-6.0.tar.gz# cd ncurses-6.0# ./configure --with-normal --with-debug --enable-overwrite# make install.libs iftop-1.0pre4 설치방법 123# tar xf iftop-1.0pre4.tar.gz # cd iftop-1.0pre4 # ./configure &amp;&amp; install Tip centos 계열에서 소스설치가 안될때는 rpm으로 설치가 가능한데 yum install yum-downloadonly 을 설치하여 rpm 다운로드 프로그램을 설치한뒤 yum install iftop –downloadonly –downloaddir=/home/user/Downloads 이런식으로 rpm 을 특정경로에 다운받아 둘 수 있다. 이를 사용하려면 다운받으려는 rpm 이 미설치된 상태어야 한다.","categories":[{"name":"기타","slug":"기타","permalink":"https://osujin.github.io/categories/기타/"}],"tags":[]},{"title":"ODL karaf 에서 impl 모듈만 빌드해서 다시 띄우는 방법","slug":"ODL-karaf-에서-impl-모듈만-빌드해서-다시-띄우는-방법","date":"2017-03-28T04:39:03.000Z","updated":"2018-04-04T05:41:37.441Z","comments":true,"path":"2017/03/28/ODL-karaf-에서-impl-모듈만-빌드해서-다시-띄우는-방법/","link":"","permalink":"https://osujin.github.io/2017/03/28/ODL-karaf-에서-impl-모듈만-빌드해서-다시-띄우는-방법/","excerpt":"","text":"ODL 개발시 impl 쪽을 수정할때마다 매번 프로젝트 전체를 빌드하고 다시 karaf를 띄우는게 시간이 오래걸려 확인해보니 karaf 내에서 각 bundle별로 죽였다 다시 띄울때 jar 파일만 교체해주면 전체를 빌드하지 않아도 손쉽게 적용이 가능하다. ~/karaf/target/assembly/system/org/opendaylight/hello/hello-service/0.1.0-SNAPSHOT/hello-Service-0.1.0-SNAPSHOT.jar 위와 같이 karaf 폴더안에 system 폴더까지 들어가보면 프로젝트의 groupId의 경로에 각종 모듈들의 jar 파일이 존재한다. 여기에 포함되어있는 jar 파일만 교체를 해주면 karaf 를 재기동 하지 않아도 수정된 bundle을 다시 띄울수 있다. 띄우는 방법은 우선 아래 명령어를 이용하여 자신이 수정한 모듈을 찾는다. 1feature:list -i 내가 수정하려는 bundle의 예는 다음과 같다. 1234odl-helloService-api | 0.1.0-SNAPSHOT | x | odl-helloService-0.1.0-SNAPSHOT | OpenDaylight :: helloService :: apiodl-helloService | 0.1.0-SNAPSHOT | x | odl-helloService-0.1.0-SNAPSHOT | OpenDaylight :: helloServiceodl-helloService-rest | 0.1.0-SNAPSHOT | x | odl-helloService-0.1.0-SNAPSHOT | OpenDaylight :: helloService :: RESTodl-helloService-ui | 0.1.0-SNAPSHOT | x | odl-helloService-0.1.0-SNAPSHOT | OpenDaylight :: helloService :: UI 이제 수정하려는 모듈인 odl-helloService 을 uninstall 한다. 1feature:uninstall odl-helloService 그리고 위에 설명한것 처럼 수정된 jar 파일을 경로에 맞게 옮겨놓고 다시 아래 명령어로 feature를 install 하면 된다. 1feature:install odl-helloService 옮겨진 jar 파일명은 당연히 기존 파일명과 동일하게 맞춰야한다. 위고하정이 정상적으로 수행이 되면 프로젝트 전체를 빌드하지 않고 특정 module만 재배포가 가능하다.","categories":[{"name":"OpenDayLight","slug":"OpenDayLight","permalink":"https://osujin.github.io/categories/OpenDayLight/"}],"tags":[]},{"title":"ODL에서 외부 라이브러리 사용하기","slug":"ODL에서-외부-라이브러리-사용하기","date":"2017-03-28T04:27:09.000Z","updated":"2018-04-04T06:50:52.374Z","comments":true,"path":"2017/03/28/ODL에서-외부-라이브러리-사용하기/","link":"","permalink":"https://osujin.github.io/2017/03/28/ODL에서-외부-라이브러리-사용하기/","excerpt":"","text":"ODL SB plugin을 만들면서 외부 라이브러리를 거의 필수적으로 사용하게 되는데 karaf상에서 외부라이브러리를 사용하는 방식이 다소 복잡하여 정리를 하였다. 내가 필요한 라이브라리는 아래와 같다. 123456789import org.springframework.http.HttpMethod;import org.springframework.http.ResponseEntity;import org.springframework.http.client.ClientHttpRequest;import org.springframework.util.LinkedMultiValueMap;import org.springframework.util.MultiValueMap;import org.springframework.web.client.RestTemplate;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.JsonNode;import com.fasterxml.jackson.databind.ObjectMapper; 위 라이브러리들은 org.springframework com.fasterxml.jackson.core 에 포함된 라이브러리 인데 기존 자바 프로젝트처럼 단순히 dependeny만 잡아준다고해서 karaf에서 bundle로 해당 SB plugin을 기동하려고 하면 라이브러리를 추가하라는 에러가 나온다. 그래서 OSGi Framework 에서 외부라이브러리를 embedded 해주는 apache felix를 pom.xml에 설정을 해주어야 정상적으로 사용이 가능하다. 위에 명시된 두개의 외부 라이브러리를 사용하기 위해 pom.xml에 dependency를 잡아주고 추가적으로 build 설정에 felix를 추가해주었다. 설정내용은 다음과 같다. 123456789101112131415161718192021222324252627282930313233&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.felix&lt;/groupId&gt; &lt;artifactId&gt;maven-bundle-plugin&lt;/artifactId&gt; &lt;extensions&gt;true&lt;/extensions&gt; &lt;configuration&gt; &lt;instructions&gt; &lt;Export-Package&gt; org.springframework.*, com.fasterxml.jackson.* &lt;/Export-Package&gt; &lt;Import-Package&gt; *;resolution:=optional &lt;/Import-Package&gt; &lt;Embed-Dependency&gt; jackson-databind;type=!pom;inline=false, spring-web;type=!pom;inline=false &lt;/Embed-Dependency&gt; &lt;Embed-Transitive&gt; true &lt;/Embed-Transitive&gt; &lt;Include-Resource&gt; &#123;maven-resources&#125; &lt;/Include-Resource&gt; &lt;_removeheaders&gt; Embed-Dependency,Include-Resource &lt;/_removeheaders&gt; &lt;/instructions&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 각 테그들에 대한 내용은 아래 문서를 보고 확인을 해봐야 할것 같다. Apache Felix Maven Bundle Plugin (BND) Documentation","categories":[{"name":"OpenDayLight","slug":"OpenDayLight","permalink":"https://osujin.github.io/categories/OpenDayLight/"}],"tags":[]},{"title":"ODL(OpenDayLight) 기본 튜토리얼 #7_4 – singletonsimple RPC Route 기능 설명","slug":"ODL(OpenDayLight)-기본-튜토리얼-7_4–singletonsimple-RPC-Route-기능-설명","date":"2017-03-18T06:08:10.000Z","updated":"2018-04-04T05:51:32.862Z","comments":true,"path":"2017/03/18/ODL(OpenDayLight)-기본-튜토리얼-7_4–singletonsimple-RPC-Route-기능-설명/","link":"","permalink":"https://osujin.github.io/2017/03/18/ODL(OpenDayLight)-기본-튜토리얼-7_4–singletonsimple-RPC-Route-기능-설명/","excerpt":"","text":"singletons cluster의 구조는 다음과 같다. [사진 1] 3개의 docker instance에 singletonsimple 를 배포하고 기동하면 자동으로 cluster 설정이 이루어 지고 Leader Node가 설정되어 진다. Leader Node는 3개의 Node중에 선택되어지고 Leader Node가 죽으면 다른 Node가 Leader가 된다. singletonsimple 프로젝트의 yang 파일을 보면 총 3개의 RPC가 존재한다. global-rpc routed.rpc local-rpc 먼저 rpc를 등록해주는 SingletonSimpleProvider.java 파일의 소스코드의 일부분을 살펴보자 1234567891011121314151617181920212223242526public class SingletonSimpleProvider implements ClusterSingletonService &#123; private ClusterSingletonServiceRegistration cssRegistration; ... ... @Override public void instantiateServiceInstance() &#123; LOG.info(\"We take Leadership\"); Preconditions.checkState(globalRpcServiceReg == null, \"Unexpected state: we have active GlobalRpcServiceRegistration\"); Preconditions.checkState(routedRpcServiceReg == null, \"Unexpected state: we have active RoutedRpcServiceRegistration\"); // Create a new instance of the Global RPC Service and register it with the RPC registry globalRpcServiceReg = rpcProviderRegistry.addRpcImplementation(GlobalRpcService.class, new GlobalRpcServiceImpl(hostInfo)); // Create a new instance of the Routed RPC Service and register it and its path with the RPC registry routedRpcServiceReg = rpcProviderRegistry.addRoutedRpcImplementation(RoutedRpcService.class, new RoutedRpcServiceImpl(hostInfo)); /* The route identifier for the registered path is as follows: * routed-rpc:rpc-member[routed-rpc:name=\"rpc-key\"] */ routedRpcServiceReg.registerPath(RoutedRpcContext.class, InstanceIdentifier.builder(RpcMember.class, new RpcMemberKey(\"rpc-key\")).build()); &#125; 위 클래스는 ClusterSingletonService를 implements 받는데 이 클래스에서 Override 된 instantiateServiceInstance 메소드에 등록된 RPC가 cluster로 묶인 Node들에서 공유가 되는 것이다. 위에서 말했듯이 자동으로 Leader Node가 설정되어지는데 리더로 설정된 Node에서만 instantiateServiceInstance 가 실행되고 나머지 Node들은 실행되지 않는다. 공식 문서에 따르면 ClusterSingletonService 에는 EOS(Entity Ownership Service)에대한 복잡한 알고리즘을 처리하는 로직이 포함되어 Leader Node가 죽을 경우 살아있는 다른 Node가 Leader가 되도록 한다. RPC 기능 설명singletonsimple 프로젝트를 보면 3개의 RPC가 선언 되어 있다고했다. 각 RPC에 대해 자세히 알아보자 1&#46;local-rpc 가장 기본적인 RPC 기능을 한다. local-rpc는 Provider class에 init 메소드에 등록이 되어 각 Node에서 karaf를 구동시킬때 자동으로 등록되어져 REST 방식으로 호출하여 사용가능하다. 2&#46;global-rpc global-rpc는 Provider class의 instantiateServiceInstance 메소드에서 등록이 되는데 instantiateServiceInstance메소드는 Leader Node에서만 실행이 된다고 하였다. Leader Node 가 instantiateServiceInstance 메소드를 실행하면 global-rpc 가 SAL에 등록이 되고 나머지 두개의 Node에도 광고가 된다. 실제로는 Leader Node에만 global-rpc가 등록되어 진것이지만 다른 두개의 Node에서도 해당 RPC를 사용 할 수 있다. 만약 Leader Node가 죽었을 경우 다른 Node가 Leader 가 되고 instantiateServiceInstance 이 실행되어 global-rpc가 등록되어진다. 위 사진1 에서는 Node1 이 Leader가 된 경우에 Leader1의 Global RPC만 접근이 가능하여 RESTCONF Global RPC 로 되어있고 Node2,3 는 RESTCONF Global RPC 라고 되어진것이 바로 이뜻이다. global-rpc를 실제로 동작시켜 보면 다음과 같다. [사진2] [사진3] 사진 2를 보면 2번 Node(172.17.0.3)에서 global-rpc를 호출 하였고 이에 대한 응답으로 다음 결과를 받았다.1234567891011121314&#123; \"output\": &#123; \"ip-address\": [ \"fe80:0:0:0:42:acff:fe11:2%eth0\", \"172.17.0.2\", \"0:0:0:0:0:0:0:1%lo\", \"127.0.0.1\" ], \"host-name\": \"member-1\", \"output-param\": \"Some input-param\", \"invocations\": 4, \"jvm-uptime\": 145673203 &#125;&#125; 응답받은 결과를 보면 host-name = member-1 , ip = 172.17.0.2 으로 출력된것을 보아 첫번째 Node의 RPC가 호출된것으로 보인다. 사진3은 ODL의 로그인데 실제로 2번 Node 에서 Global rpc를 호출 했지만 실제로 응답한것은 1번 Node라는것을 확인 할 수 있다. 다음으로 1번 Node를 강제로 죽여 Leader Node를 변경하여 보자. [사진4] 위 그림4를 보면 1번 Node의 ODL을 죽이면 자동으로 2,3번 Node로 1번 Node가 죽었다는 Notification이 날라가고 Leader 선출 과정을 거쳐 2번 Node가 Leader로 선출 되었음을 알 수 있다. 3&#46;routed-rpc routed rpc의 동작방식은 global rpc와 거의 동일하다. 다른점이 있다면 instantiateServiceInstance메소드에서 RPC를 등록할때에 RpcMemberKey를 설정할수 있는데 routed-rpc를 호출할때 여기서 설정한 key 값을 이용해 호출을 할 수 있다. routed-rpc 역시 Leader Node에서만 등록이되어 사용이 가능하고 호출은 어떤 노드에서나 가능하다. [사진5] 링크 : OpenDaylight OpenFlow Plugin:Clustering Singleton","categories":[{"name":"OpenDayLight","slug":"OpenDayLight","permalink":"https://osujin.github.io/categories/OpenDayLight/"}],"tags":[]},{"title":"ODL(OpenDayLight) 기본 튜토리얼 #7_3 – clustering 설정","slug":"ODL(OpenDayLight)-기본-튜토리얼-7_3-–-clustering-설정","date":"2017-03-17T08:11:02.000Z","updated":"2018-04-04T05:47:33.892Z","comments":true,"path":"2017/03/17/ODL(OpenDayLight)-기본-튜토리얼-7_3-–-clustering-설정/","link":"","permalink":"https://osujin.github.io/2017/03/17/ODL(OpenDayLight)-기본-튜토리얼-7_3-–-clustering-설정/","excerpt":"","text":"앞선 예제에서 사용했던 hello 프로젝트를 clustering을 이용하도록 구현해보자. 목표는 global-rpc,routed-rpc 구현과 datastore 공유이다. hello 프로젝트에 아무런 설정을 하지 않고 1ansible-playbook -i hosts playbook_hello.yaml 명령어를 이용하여 3개의 docker instance로 배포를한뒤 karaf를 실행시키고 hello-world-write RPC 를 이용하여 datastore에 데이터를 저장하면 3개의 노드 전부 datastore가 복제된다. DataChangeListener의 경우에는 3개 Node에서 전부 실행 되는게 아니라 특정 Node 한곳에서만 실행이 되는듯 해보이는데 이건 좀더 분석을 해봐야 할것 같다. 이제 coretutorials에 있는 singletonsimple 을 직접 hello 프로젝트에 구현을 해보자 일단 기존에 생성된 hello 프로젝트는 ODL lithium 버전으로 만들어져서 이걸 boron 버전으로 변경해줘야 한다. 그런데 lithium 버전은 blueprint를 사용하지 않기 때문에 수동으로 impl 모듈에 blueprint.xml 파일을 넣어주고 기존에 만들어진 module yang 관련 파일은 삭제를 해줘야 한다. 123impl/src/main 하위에 resources 를 만들고 폴더명이 org/opendaylight/blueprint 인 package 폴더를 만들고 impl-blueprint.xml 파일을 만들어 준다.폴더를 생성할때 꼭 확인을 해야 할것이 폴더명이 org.opendaylight.blueprint 으로 되지 않았는지 확인이 필요하다. 폴더구조의 형태로 만들어져야 한다. impl-blueprint.xml 파일 내용은 아래와 같다. 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!-- vi: set et smarttab sw=4 tabstop=4: --&gt; &lt;!--Copyright © 2016 Copyright(c) Chun, Inc. and others. All rights reserved. This program and the accompanying materials are made available under theterms of the Eclipse Public License v1.0 which accompanies this distribution,and is available at http://www.eclipse.org/legal/epl-v10.html--&gt;&lt;blueprint xmlns=\"http://www.osgi.org/xmlns/blueprint/v1.0.0\" xmlns:odl=\"http://opendaylight.org/xmlns/blueprint/v1.0.0\" odl:use-default-for-reference-types=\"true\"&gt; &lt;reference id=\"dataBroker\" interface=\"org.opendaylight.controller.md.sal.binding.api.DataBroker\" odl:type=\"default\" /&gt; &lt;reference id=\"rpcRegistry\" interface=\"org.opendaylight.controller.sal.binding.api.RpcProviderRegistry\"/&gt; &lt;reference id=\"notificationService\" interface=\"org.opendaylight.controller.md.sal.binding.api.NotificationPublishService\"/&gt; &lt;reference id=\"clusterSingletonService\" interface=\"org.opendaylight.mdsal.singleton.common.api.ClusterSingletonServiceProvider\"/&gt; &lt;bean id=\"provider\" class=\"org.opendaylight.hello.impl.HelloProvider\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;argument ref=\"dataBroker\" /&gt; &lt;argument ref=\"rpcRegistry\" /&gt; &lt;argument ref=\"notificationService\" /&gt; &lt;argument ref=\"clusterSingletonService\" /&gt; &lt;/bean&gt; &lt;/blueprint&gt; impl-blueprint.xml 파일에서 수정해야 할 부분은 bean 설정에서 class 명을 자신이 생성한 provider class와 일치해주면 된다. blueprint 설정이 끝났으면 기존에 lithium 버전에서 사용했던 파일들을 삭제해줘야 정상적으로 blueprint 사용이 가능하다. 삭제할 파일 및 폴 test 폴더 main/yang 폴더 config 폴더 java/org/opendaylight 하위에 있는 yang 풀더 다음으로 각 모듈의 pom 파일을 수정해야 한다. impl 모듈의 pom.xml : version -&gt; 0&#46;5.2-Boron-SR2 으로 변경 root pom.xml : version -&gt; 1&#46;7.2-Boron-SR2 으로 변경 api 모듈의 pom.xml : version -&gt; 0&#46;9.2-Boron-SR2 으로 변경 artifacts 모듈의 pom.xml : version -&gt; 1&#46;8.0-SNAPSHOT 으로 변경 karaf 모듈의 pom.xml : version -&gt; 1&#46;7.2-Boron-SR2 으로 변경 feature 모듈의 pom.xml : version -&gt; 1&#46;7.2-Boron-SR2 으로 변경 , properties tag 안의 내용을 아래와 같이 변경 12345678&lt;properties&gt; &lt;mdsal.model.version&gt;0.10.0-SNAPSHOT&lt;/mdsal.model.version&gt; &lt;mdsal.version&gt;1.5.0-SNAPSHOT&lt;/mdsal.version&gt; &lt;restconf.version&gt;1.5.0-SNAPSHOT&lt;/restconf.version&gt; &lt;yangtools.version&gt;1.1.0-SNAPSHOT&lt;/yangtools.version&gt; &lt;dlux.version&gt;0.5.0-SNAPSHOT&lt;/dlux.version&gt; &lt;configfile.directory&gt;etc/opendaylight/karaf&lt;/configfile.directory&gt;&lt;/properties&gt; 다음엔 HelloProvider.java 파일을 boron 버전에 맞게 수정해줘야 한다. 아래 코드는 소스의 일부분인데 implements 부분이 변경 되었고 생성자로 blueprint 에서 넘겨주는 값을 받도록 설정 하였다. 그리고 ClusterSingletonService 인터페이스의 메소드인 instantiateServiceInstance 메소드에 global rpc 서비스를 등록해주어 singleton cluster 사용을 하도록 수정해준다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class HelloProvider implements ClusterSingletonService &#123; private static final Logger LOG = LoggerFactory.getLogger(HelloProvider.class); private DataBroker db; private RpcRegistration&lt;HelloService&gt; helloService; private InstanceIdentifier&lt;HelloWorld&gt; path; private ListenerRegistration&lt;DataChangeListener&gt; data_change_listener; private final HostInformation hostInfo = new HostInformation(); //boron version private final RpcProviderRegistry rpcProviderRegistry; private final NotificationPublishService notificationPublishService; private final ClusterSingletonServiceProvider clusterSingletonServiceProvider; private ClusterSingletonServiceRegistration cssRegistration; private RpcRegistration&lt;GlobalRpcService&gt; globalRpcServiceReg; private static final ServiceGroupIdentifier IDENT = ServiceGroupIdentifier.create(\"Brm\"); public HelloProvider(final DataBroker dataBroker, final RpcProviderRegistry rpcProviderRegistry, final NotificationPublishService notificationPublishService, final ClusterSingletonServiceProvider clusterSingletonServiceProvider) &#123; this.db = dataBroker; this.rpcProviderRegistry = rpcProviderRegistry; this.notificationPublishService = notificationPublishService; this.clusterSingletonServiceProvider = clusterSingletonServiceProvider; &#125; public void init() &#123; LOG.info(\"HelloProvider Session Initiated\"); HelloWorldImpl helloWorldImpl=new HelloWorldImpl(); this.path=helloWorldImpl.HELLO_IID; helloWorldImpl.setDb(this.db); //registerDataChangeListener(접근하고자 하는 데이터 트리 종류(config or operational), 데이터 트리 PATH(InstanceIdentifier로 정의),실행될 객체, 변화감지 범위); this.data_change_listener=this.db.registerDataChangeListener(LogicalDatastoreType.CONFIGURATION,path,helloWorldImpl,DataChangeScope.SUBTREE); //boron cssRegistration = clusterSingletonServiceProvider.registerClusterSingletonService(this); this.helloService = rpcProviderRegistry.addRpcImplementation(HelloService.class,helloWorldImpl); &#125; public void close() throws Exception &#123; LOG.info(\"HelloProvider Closed\"); if (cssRegistration != null) &#123; try &#123; cssRegistration.close(); &#125; catch (final Exception e) &#123; LOG.warn(\"Unexpected close exception\", e); &#125; cssRegistration = null; &#125; if (helloService != null) &#123; helloService.close(); helloService = null; &#125; &#125; @Override public void instantiateServiceInstance() &#123; LOG.info(\"We take Leadership\"); Preconditions.checkState(globalRpcServiceReg == null, \"Unexpected state: we have active GlobalRpcServiceRegistration\"); // Create a new instance of the Global RPC Service and register it with the RPC registry globalRpcServiceReg = rpcProviderRegistry.addRpcImplementation(GlobalRpcService.class, new GlobalRpcServiceImpl(hostInfo)); &#125; @Override public ListenableFuture&lt;Void&gt; closeServiceInstance() &#123; LOG.info(\"We lost Leadership\"); // Unregister the Global RPC instance if (globalRpcServiceReg != null) &#123; globalRpcServiceReg.close(); globalRpcServiceReg = null; &#125; return Futures.immediateFuture(null); &#125; @Override public ServiceGroupIdentifier getIdentifier() &#123; return IDENT; &#125;&#125; global-rpc를 사용하기 위해서는 features.xml 에 odl-mdsal-clustering 를 등록해줘야 한다. 1234567&lt;feature name='odl-hello' version='$&#123;project.version&#125;' description='OpenDaylight :: hello'&gt; &lt;feature version='$&#123;mdsal.version&#125;'&gt;odl-mdsal-broker&lt;/feature&gt; &lt;feature version='$&#123;project.version&#125;'&gt;odl-hello-api&lt;/feature&gt; &lt;feature version='$&#123;mdsal.version&#125;'&gt;odl-mdsal-clustering&lt;/feature&gt; &lt;bundle&gt;mvn:org.opendaylight.hello/hello-impl/&#123;&#123;VERSION&#125;&#125;&lt;/bundle&gt; &lt;configfile finalname=\"$&#123;configfile.directory&#125;/hello.xml\"&gt;mvn:org.opendaylight.hello/hello-impl/&#123;&#123;VERSION&#125;&#125;/xml/config&lt;/configfile&gt;&lt;/feature&gt; 마지막으로 singletonsimple 프로젝트의 yang 파일중에 commons.yang , global-rpc.yang 파일을 hello 프로젝트의 api 폴더에 있는 yang 폴더로 옮겨주고 GlobalRpcServiceImpl.java , HostInformation.java 파일도 impl/src/main/java 하위에 HelloProvider.java 파일이 있는곳에 옮겨주면 singletonsimple 에서 구현된 global-rpc 를 사용 할 수 있다.","categories":[{"name":"OpenDayLight","slug":"OpenDayLight","permalink":"https://osujin.github.io/categories/OpenDayLight/"}],"tags":[]},{"title":"ODL(OpenDayLight) 기본 튜토리얼 #7_2 – ODL Clustering 소스 배포","slug":"ODL(OpenDayLight)-기본-튜토리얼-7_2-–-ODL-Clustering-소스-배포","date":"2017-03-13T06:35:22.000Z","updated":"2018-04-04T05:37:24.254Z","comments":true,"path":"2017/03/13/ODL(OpenDayLight)-기본-튜토리얼-7_2-–-ODL-Clustering-소스-배포/","link":"","permalink":"https://osujin.github.io/2017/03/13/ODL(OpenDayLight)-기본-튜토리얼-7_2-–-ODL-Clustering-소스-배포/","excerpt":"","text":"이번에는 앞서 구축한 3개의 docker instance에 소스를 배포하고 기동하는 방법이다. 테스트 소스는 coretutorials/clustering 하위에 있는 singletonsimple 으로 하겠다. 먼저 singletonsimple 을 빌드를 해야 하는데 singletonsimple-impl 를 빌드하다 문제가 발생했었다. [ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.4.1:enforce 위와 같은 에러였는데 singletonsimple-impl/pom.xml 파일에 parent 버전정보를 불러오는 곳이 있는데 기존에 있던 1.8.0-SNAPSHOT 해당 버전이 존재하지 않아 발생한것 같다. 이부분을 Boron 버전중에 하나로 설정해주면 된다. 필자는 0.5.2-Boron-SR2 버전을 사용하였다. 빌드를 완료했으면 각 instance로 배포를 해야 한다. 문서에 나와 있는 ansible을 이용하여 배포해보도록 하겠다. ansible을 이용하기전에 한가지 작업해줄게 있다. docker로 띄운 3개의 instance에 /opt/scripts/ 폴더를 생성하고 coretutorials/clustering/node/install_odl.sh, configure-cluster-ipdetect.sh 파일을 복사해주어야 한다. ansible 설치 방법은 구글을 참조하길 바란다. ansible로 소스 배포하기_ docker-Host $ cd coretutorials/clustering/scripts/ansible docker-Host $ ansible-playbook -i hosts playbook.yaml playbook.yaml 파일내용을 약간 수정을 해줘야 하는데 파일을 열어보면 distro_name: singletonsimple-karaf-0.1.0-SNAPSHOT.zip local_path: /Users/jmedved/Documents/ODL/Git/coretutorials/clustering/singletonsimple/karaf/target 위 두줄이 있는데 distro_name 부분에 자신이 배포하고 싶은 소스명을 적고 local_path 부분에 해당 소스가 있는 경로를 적어주면 된다. 배포되는 소스는 zip 으로 압축된것을 보낸다. 수동으로 배포하는 방법도 알아보자 singletonsimple을 빌드하면 singletonsimple/karaf/target 하위에 컴파일된 파일들이 있는데 .zip 으로 된 파일을 docker instance 들에게 ftp등을 이용하여 전송하면된다.\\ 전송한뒤에는 앞서 옮긴 install_odl.sh 파일을 이용하여 cluster 셋팅을 해주어야 한다. 1member 1~3 # /opt/scripts/install_odl.sh -d [컴파일된 소스가 저장될 경로] – i [Zip 파일명] -p [Zip 파일 경로] -c [클러스터를 형성할 3개의 instance들의 IP] EX.) &gt; member 1~3 # /opt/scripts/install_odl.sh -d /opt/odl – i example-karaf-0.1.0-SNAPSHOT.zip -p . -c ‘172.17.0.2 172.17.0.3 172.17.0.4’ configure-cluster-ipdetect.sh 파일을 열어보면 zip/configuration에 initial폴더를 생성하고 akka.conf , module-shards.conf , modules.conf 3개의 파일을 생성하는데 akka.conf 파일에 cluster를 형성할 instance들의 ip 정보가 담겨져 있다. ODL Cluster구성은 akka framework를 이용해서 구성을 하는듯 하다. akka 설정을 통해 cluster node를 설정할 수 있고 손쉽게 여러개의 cluster node 구현이 가능하다. Multiple Node Clustering 공식 문서","categories":[{"name":"OpenDayLight","slug":"OpenDayLight","permalink":"https://osujin.github.io/categories/OpenDayLight/"}],"tags":[]},{"title":"ODL(OpenDayLight) 기본 튜토리얼 #7_1 – ODL Cluster 환경 구축","slug":"ODL(OpenDayLight)-기본-튜토리얼-7_1-–-ODL-Cluster-환경-구축","date":"2017-03-13T05:44:04.000Z","updated":"2018-04-04T05:35:11.645Z","comments":true,"path":"2017/03/13/ODL(OpenDayLight)-기본-튜토리얼-7_1-–-ODL-Cluster-환경-구축/","link":"","permalink":"https://osujin.github.io/2017/03/13/ODL(OpenDayLight)-기본-튜토리얼-7_1-–-ODL-Cluster-환경-구축/","excerpt":"","text":"3개의 가상 Host를 이용하여 ODL cluster를 테스트 할수 있는 환경 구축해보도록 한다. 테스트에 사용된 자료는 OpenDayLight Core Tutorials 이다. 다운 받도록 하자. git clone https://git.opendaylight.org/gerrit/coretutorials.git 소스를 다운받으면 clustering 폴더 안에 script shardingsimple singletonhs singletonsimple src 위와 같이 3개의 Maven 프로젝트가 있는데 이중 script 폴더는 cluster 환경을 구축하고 소스를 배포하는데 필요한 스크립트와 메뉴얼이 있고 나머지 3개의 폴더는 각각 cluster를 활용한 프로젝트이다.(src 폴더는 무시하도록하자) 지금부터는 scipts/site/asciidoc 폴더에 있는 scripts-user-manual.adoc 파일을 기반으로 설명하도록 하겠다. scripts-user-manual.adoc 파일을 보면 docker를 이용하여 3개의 가상 호스트를 띄우고 ansible을 이용하여 컴파일된 소스를 각각의 호스트에 자동으로 배포하는 방법이 설명되어 있다. 1. Docker 를 이용하여 3개의 Host 띄우기 당연한 얘기지만 일단 google 검색을 이용하여 docker를 설치한뒤 다음 명령어들을 입력해줍니다. docker image는 ubuntu가 설치 됩니다. 작업할때는 root 로 하였는데 일반계정으로 작업 하고 싶으시면 docker 권한 설정을 하시면 됩니다. 필수사항 : jre 1.8 123456789root # cd coretutorials/clustering/scripts/node //git 에서 다운받은 소스에 포함도니 docker 생성 파일을 이용하기 위해 root # docker build -t clustering/odlbase:v1.1 . //docker container 생성 root # docker images ex.) [root@ODL-Cluster#1 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE clustering/odlbase v1.1 be2bcc26a885 4 days ago 518 MB ubuntu 16.04 0ef2e08ed3fa 13 days ago 130 MB 12foo@bar:~$ whoamifoo 123456789root # docker save -o odl-base.tar clustering/odlbase:v1.1//container 저장root # docker load -i odl-base.tar//위에서 저장한 docker container 가 재대로 생성이 되는지 확인하기 위해root # docker run -d –name member-1 -h member-1 clustering/odlbase:v1.1//3개의 인스턴트 실행root # docker run -d –name member-2 -h member-2 clustering/odlbase:v1.1 # docker run -d –name member-3 -h member-3 clustering/odlbase:v1.1root # docker ps// docker instance 실행 확인 여기까지 문제 없이 했다면 3개의 docker instance가 떠있을것이다. 각 instance에 접속하는 방법은 ssh root@172.17.0.2 ssh root@172.17.0.3 ssh root@172.17.0.4 으로 비밀번호는 docker123 이다. 다음으로 ssh인증키 설정이다. 123인증키 생성 방법$ ssh-keygen -t rsa//id_rsa.pub , id_rsa 파일 생성 docker를 설치한 호스트의 ~/.ssh/authorized_keys에 위에서 실행한 3개의 docker instance의 id_rsa.pub 파일을 복사해준다. ssh-copy-id &lt;username&#62;@&lt;host&#62; 혹은 수동으로 직접 id_rsa.pub 파일을 authorized_keys에 등록해주어도 된다. docker host에는 3개 instance 의 id_rsa.pub 파일을 등록해주면 되고 instance 3개에는 docker host의 id_rsa.pub 파일을 등록해주면 된다. 여기까지 ODL clustering 을 실행 할 수 있는 환경설정이다.","categories":[{"name":"OpenDayLight","slug":"OpenDayLight","permalink":"https://osujin.github.io/categories/OpenDayLight/"}],"tags":[]},{"title":"ODL 개발시 삽질 내역..","slug":"ODL-개발시-삽질-내역..","date":"2017-03-08T07:42:42.000Z","updated":"2018-04-04T05:26:13.512Z","comments":true,"path":"2017/03/08/ODL-개발시-삽질-내역../","link":"","permalink":"https://osujin.github.io/2017/03/08/ODL-개발시-삽질-내역../","excerpt":"","text":"빌드를 하다 난 에러1234567[ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.4.1:enforce (enforce-banned-dependencies) on project singletonsimple-impl: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed. -&gt; [Help 1][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException 위 에러는 odl repository에서 버전을 찾지 못해 발생한 경우인데 이경우 impl을 빌드하다 발생 하였다 조치방법은 123456&lt;parent&gt; &lt;groupId&gt;org.opendaylight.controller&lt;/groupId&gt; &lt;artifactId&gt;config-parent&lt;/artifactId&gt; &lt;version&gt;0.6.0-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt; 위에서 parent의 version을 찾지 못해 발생한건데 version 정보를 변경해주면 된다.","categories":[{"name":"OpenDayLight","slug":"OpenDayLight","permalink":"https://osujin.github.io/categories/OpenDayLight/"}],"tags":[]},{"title":"ODL(OpenDayLight) 기본 튜토리얼 #6 – DataChangeListener 구현","slug":"ODL(OpenDayLight)-기본-튜토리얼-6-DataChangeListener-구현","date":"2017-03-07T08:26:27.000Z","updated":"2018-04-04T05:24:07.603Z","comments":true,"path":"2017/03/07/ODL(OpenDayLight)-기본-튜토리얼-6-DataChangeListener-구현/","link":"","permalink":"https://osujin.github.io/2017/03/07/ODL(OpenDayLight)-기본-튜토리얼-6-DataChangeListener-구현/","excerpt":"","text":"DataStore에 값이 저장되거나 변경 , 삭제가 되면 변경상태를 감지하는 DataChangeListener 를 구현해보도록한다. 먼저 HelloProvider.java 에서 DataChangeListener를 등록해준다 CONFIGURATION tree 만 감시하도록 구현하였다. 12345678910111213141516private DataBroker db; private InstanceIdentifier path; private ListenerRegistration data_change_listener; @Override public void onSessionInitiated(ProviderContext session) &#123; LOG.info(\"HelloProvider Session Initiated\"); HelloWorldImpl helloWorldImpl=new HelloWorldImpl(); this.path=helloWorldImpl.HELLO_IID; this.db=session.getSALService(DataBroker.class); helloWorldImpl.setDb(session); //registerDataChangeListener(접근하고자 하는 데이터 트리 종류(config or operational), 데이터 트리 PATH(InstanceIdentifier로 정의),실행될 객체, 변화감지 범위); this.data_change_listener=this.db.registerDataChangeListener(LogicalDatastoreType.CONFIGURATION,path,helloWorldImpl,DataChangeScope.SUBTREE); this.helloService=session.addRpcImplementation(HelloService.class,helloWorldImpl); &#125; 다음으론 기존 HelloWorldImpl.java 에 DataChangeListener를 implements 해주고 onDataChanged 를 구현한다. 12345678910@Override public void onDataChanged(AsyncDataChangeEvent&amp;lt;InstanceIdentifier&lt;?&gt;, DataObject&gt; change) &#123; DataObject data_object=change.getUpdatedSubtree(); if(data_object instanceof HelloWorld)&#123; HelloWorld hello=(HelloWorld)data_object; Long count=hello.getCounter(); LOG.info(\"updated count:\"+count); &#125; &#125; [결과] 1updated count:0","categories":[{"name":"OpenDayLight","slug":"OpenDayLight","permalink":"https://osujin.github.io/categories/OpenDayLight/"}],"tags":[]},{"title":"ODL(OpenDayLight) 기본 튜토리얼 #5 – DataStore 구현","slug":"ODL(OpenDayLight)-기본-튜토리얼-5-–-DataStore-구현","date":"2017-03-07T07:57:33.000Z","updated":"2018-04-04T05:21:47.426Z","comments":true,"path":"2017/03/07/ODL(OpenDayLight)-기본-튜토리얼-5-–-DataStore-구현/","link":"","permalink":"https://osujin.github.io/2017/03/07/ODL(OpenDayLight)-기본-튜토리얼-5-–-DataStore-구현/","excerpt":"","text":"이번에는 DataStore를 구현해보도록 하겠다. 아래와 같이 단순한 구조로 ODL의 dataStore를 사용하는 방법을 알아보자 역시 가장먼저 구현 해줘야 하는것은 Yang 파일이다. 기존에 만들어놓은 hello.yang 파일을 조금 수정하도록 한다. hello.yang 파일에 아래와 같이 container 를 하나 선언해준다. 12345678910111213container helloWorld&#123; leaf counter&#123; type uint32; config true; default 100; &#125; leaf value&#123; type string; config false; mandatory false; &#125; &#125; 그리고 나서 HelloWorldImpl.java 파일에서 RPC가 호출됬을 경우 DataStore에 넘겨진 값을 저장도록 구현한다. 그전에 HelloWorldImpl.java 에서 DataBroker를 사용하기 위해 HelloProvider.java 에서 session을 넘겨줘야 한다. HelloProvider.java12345678@Override public void onSessionInitiated(ProviderContext session) &#123; LOG.info(\"HelloProvider Session Initiated\"); HelloWorldImpl helloWorldImpl=new HelloWorldImpl(); helloWorldImpl.setDb(session); //HelloWorldImpl class로 session을 넘겨 사용하도록 해준다. this.helloService=session.addRpcImplementation(HelloService.class,helloWorldImpl); &#125; HelloWorldImpl.java hello-world-write RPC가 호출되면 strin 으로 넘겨온 값을 저장하도록 구현한다. OPERATIONAL tree에는 strin 값이 저장되게 하고 CONFIGURATION tree 에는 DataStore에 값이 저장될때마다 helloCounter 값이 1씩 증가된값을 저장하도록 한다. OPERATIONAL : 네트워크 상태의 변경이 감지되면 현재 네트워크 상태를 저장 CONFIGURATION : 네트워크 장비의 설정을 변경하려는 요청이 저장. 즉 네트워크 구성에 대한 request 요청이 오면 CONFIGURATION tree에 데이터가 저장되고 실제 네트워크 장비에 명령을 내려 설정을 마치면 변경된 정보가 OPERATIONAL tree에 저장이 된다. Q4. Which data is stored in MD-SAL config datastore and operational datastore? A. The config store is where “requests” are stored and the operational store is where “network state as discovered from the network” is stored. So Flows are requested by being placed in the config store, but after they are configured on the NE and ODL “discovers” them that data is put in the operational store. 1234567891011121314151617181920212223242526272829303132333435public void setDb(BindingAwareBroker.ProviderContext session)&#123; this.db=session.getSALService(DataBroker.class); this.session = session; &#125; public Future&lt;RpcResult&lt;HelloWorldWriteOutput&gt;&gt; helloWorldWrite(HelloWorldWriteInput input)&#123; final ReadWriteTransaction tx=db.newReadWriteTransaction(); tx.put(LogicalDatastoreType.OPERATIONAL,HELLO_IID,new HelloWorldBuilder().setValue(input.getStrin()).build()); tx.put(LogicalDatastoreType.CONFIGURATION,HELLO_IID,new HelloWorldBuilder().setCounter(helloCounter++).build()); try&#123; tx.submit().get(); &#125;catch(InterruptedException e)&#123; System.out.println(e.getMessage()); &#125;catch(ExecutionException e)&#123; System.out.println(e.getMessage()); &#125; //Noti 호출 NotificationProviderService notiService = session.getSALService(NotificationProviderService.class); NotiUpdatedBuilder builder = new NotiUpdatedBuilder(); builder.setNotiId(input.getStrin()); notiService.publish(builder.build()); // HelloWorldWriteOutputBuilder helloWriteBuilder=new HelloWorldWriteOutputBuilder(); helloWriteBuilder.setStrout(\"return\"+input.getStrin()); return RpcResultBuilder.success(helloWriteBuilder.build()).buildFuture(); &#125; 결과: 123456[데이터전송]POST : http://localhost:8181/restconf/operations/hello:hello-world-writedata : &#123;&quot;hello:input&quot;: &#123; &quot;strin&quot;:&quot;test1&quot;&#125;&#125; [데이터확인]GET : http://localhost:8181/restconf/config/hello:helloWorld/GET : http://localhost:8181/restconf/operational/hello:helloWorld/ http://localhost:8181/apidoc/explorer/index.html 에 접속하여 위와 같이 데이터를 전송하면 실습이 가능하다. 최종적으로는 operational tree 에는 strin 으로 전달된 데이터가 저장되고 operational tree에는 helloCounter 값이 저장된다.","categories":[{"name":"OpenDayLight","slug":"OpenDayLight","permalink":"https://osujin.github.io/categories/OpenDayLight/"}],"tags":[]},{"title":"ODL(OpenDayLight) 기본 튜토리얼 #4 – Notification 구현","slug":"ODL(OpenDayLight)-기본-튜토리얼-4-Notification-구현","date":"2017-03-07T04:43:20.000Z","updated":"2018-04-04T05:12:34.345Z","comments":true,"path":"2017/03/07/ODL(OpenDayLight)-기본-튜토리얼-4-Notification-구현/","link":"","permalink":"https://osujin.github.io/2017/03/07/ODL(OpenDayLight)-기본-튜토리얼-4-Notification-구현/","excerpt":"","text":"ODL에서 사용하는 Notification의 개념은 RPC와 비슷하다고 생각하면 되는데 차이점이 있다면 Notification은 return값이 없다는것이다. 새로운 impl module을 추가하고 폴더명을 notificationService로 변경하고 artifactId 는 notification 로 바꿔준다. 현재 프로젝트 구조는 아래와 같다. 먼저 notificationService 에서 사용될 yang 파일을 만들어 준다. 12345678910111213module notification-manager &#123; yang-version 1; namespace &quot;urn:opendaylight:params:xml:ns:yang:notification-manager&quot;; prefix &quot;inventory-manager&quot;; revision &quot;2015-01-05&quot; &#123; description &quot;Initial revision of ptnTest model&quot;; &#125; notification noti-updated &#123; leaf noti-id &#123; type string; &#125; &#125; &#125; 이어서 NotificationProvider.java 에 notification을 등록해준다. 1234567@Override public void onSessionInitiated(ProviderContext session) &#123; LOG.info(\"NotificationProvider Session Initiated\"); NotificationProviderService noti = session.getSALService(NotificationProviderService.class); noti.registerNotificationListener(new NotificationImpl()); &#125; NotificationImpl.java 를 생성하고 위에서 생성한 yang 파일을 implements 한뒤 onNotiUpdated 메서드를 구현해준다. 123456789public class NotificationImpl implements NotificationManagerListener &#123; private static final Logger LOG = LoggerFactory.getLogger(NotificationImpl.class); @Override public void onNotiUpdated(NotiUpdated notification) &#123; LOG.info(\"Receive Noti : \"+notification.getNotiId()); &#125;&#125; 이제 NotificationListener를 수현했으면 호출해서 사용만 하면 된다. 아래 예제에서는 hello-world-write RPC가 호출되면 전달된 값을 notificationService 로 넘기도록 하였다. 123456789101112131415public Future&lt;RpcResult&lt;HelloWorldWriteOutput&gt;&gt; helloWorldWrite(HelloWorldWriteInput input)&#123; //Noti 호출부분 NotificationProviderService notiService = session.getSALService(NotificationProviderService.class); NotiUpdatedBuilder builder = new NotiUpdatedBuilder(); builder.setNotiId(input.getStrin()); notiService.publish(builder.build()); // //RPC result return HelloWorldWriteOutputBuilder helloWriteBuilder=new HelloWorldWriteOutputBuilder(); helloWriteBuilder.setStrout(&quot;return&quot;+input.getStrin()); return RpcResultBuilder.success(helloWriteBuilder.build()).buildFuture(); &#125; 이제 위 예제를 돌려보아 다음과 같은 결과가 표시되면 정상적으로 동작한것이다. RPC 호출 {“hello:input”: { “strin”:”test1”}} 을 post 방식으로 전달해주면 return 으로 다음과 같은 결과를 받는다. 12345&#123; \"output\": &#123; \"strout\": \"returntest1\" &#125;&#125; Notification 호출 hello-world-write RPC를 호출하면 전달받은 strin 값을 notificationService 으로 전달한다. 12017-03-07 13:18:37,623 | INFO | pool-28-thread-1 | NotificationImpl | 161 -org.opendaylight.hello.notification - 1.0.0.SNAPSHOT | Receive Noti : test1","categories":[{"name":"OpenDayLight","slug":"OpenDayLight","permalink":"https://osujin.github.io/categories/OpenDayLight/"}],"tags":[]},{"title":"ODL(OpenDayLight) 기본 튜토리얼 #3 – RPC 구현","slug":"ODL(OpenDayLight)-기본-튜토리얼-3-–-RPC-구현","date":"2017-03-06T08:23:36.000Z","updated":"2018-04-04T05:02:50.723Z","comments":true,"path":"2017/03/06/ODL(OpenDayLight)-기본-튜토리얼-3-–-RPC-구현/","link":"","permalink":"https://osujin.github.io/2017/03/06/ODL(OpenDayLight)-기본-튜토리얼-3-–-RPC-구현/","excerpt":"","text":"Yang파일에 RPC 선언RPC를 구현하기 위해선 yang파일에 rpc를 선언해줘야 한다. 123456789101112131415161718192021222324252627282930313233343536module hello &#123; yang-version 1; namespace &quot;urn:opendaylight:params:xml:ns:yang:hello&quot;; prefix &quot;hello&quot;; revision &quot;2015-01-05&quot; &#123; description &quot;Initial revision of hello model&quot;; &#125; rpc hello-world-write&#123; input&#123; leaf strin&#123; type string; &#125; &#125; output&#123; leaf strout&#123; type string; &#125; &#125; &#125; rpc hello-world-read&#123; input&#123; leaf strin&#123; type string; &#125; &#125; output&#123; leaf strout&#123; type string; &#125; &#125; &#125; &#125; 위 yang 파일에선 hello-world-write , hello-world-read 두개의 RPC를 선언했다. yang 파일을 만든 후 api module을 bulid 하면 target 밑에 java source code가 생성된다. xxxProvider.java 파일에 RPC 등록karaf를 구동하면 Impl module이 자동으로 기동되는데 xxxProvider.java 파일에 있는 onSessionInitiated 메소드에 RPC를 등록해주어 사용이 가능하도록 해준다. 1234567private RpcRegistration&lt;HelloService&gt; helloService; @Override public void onSessionInitiated(ProviderContext session) &#123; LOG.info(\"HelloProvider Session Initiated\"); this.helloService=session.addRpcImplementation(HelloService.class,helloWorldImpl); &#125; 위 소스의 설명을 하면 private RpcRegistration helloService; 에서 HelloService 는 위에 생성한 yang 파일의 모듈명이다. 예제에선 hello 라는 이름으로 모듈을 생성했고 RPC로 생성될때는 $module명+Service = HelloService 라고 생성되는것이다.그리고 실제로 RPC가 작동할 helloWorldImpl.java 를 생성해주고 RPC interface를 구현해준다. helloWorldImpl.java 구현helloWorldImpl.java는 HelloService 를 implements 받아 생성된 메서드를 구현해줘야 한다. 위의 yang 파일에선 hello-world-write , hello-world-read 두가지 RPC를 선언했으므로 두개의 메서드를 implements 받아 구현한다. 12345678910111213141516171819202122public Future&lt;RpcResult&lt;HelloWorldWriteOutput&gt;&gt; helloWorldWrite(HelloWorldWriteInput input)&#123; HelloWorldWriteOutputBuilder helloWriteBuilder=new HelloWorldWriteOutputBuilder(); helloWriteBuilder.setStrout(\"return\"+input.getStrin()); return RpcResultBuilder.success(helloWriteBuilder.build()).buildFuture(); &#125; public Future&lt;RpcResult&lt;HelloWorldReadOutput&gt;&gt; helloWorldRead(HelloWorldReadInput input)&#123; HelloWorldReadOutputBuilder helloReadBuilder=new HelloWorldReadOutputBuilder(); try&#123; helloReadBuilder.setStrout(\"Echo :: \"+input.getStrin()); &#125;catch(InterruptedException e)&#123; System.out.println(e.getMessage()); &#125;catch(ExecutionException e)&#123; System.out.println(e.getMessage()); &#125; return RpcResultBuilder.success(helloReadBuilder.build()).buildFuture(); &#125; 내용추가 impl 빌드 할때 Line does not match expected header 에러가 발생하면 impl 의 pom.xml 파일에 아래 내용을 추가해주면 된다. 12345678&lt;build&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/build&gt; 실행 결과 http://localhost:8181/apidoc/explorer/index.html 으로 접속하면 REST API를 호출할수 있는 화면이 나온다. 위에서 생성한 yang 파일의 모듈명을 찾으면 아래와 같이 두가지 POST request가 나온다. 각각을 선택하여 {“hello:input”: { “strin”:”OpenDayLight”}} 이라는 메시지를 전송하면 이에대한 응답이 올것이다.","categories":[{"name":"OpenDayLight","slug":"OpenDayLight","permalink":"https://osujin.github.io/categories/OpenDayLight/"}],"tags":[]},{"title":"ODL(OpenDayLight) 기본 튜토리얼 #2 – Impl 추가(Lithium Version)","slug":"ODL(OpenDayLight)-기본-튜토리얼-2-–-Impl-추가(Lithium-Version)","date":"2017-03-06T07:04:53.000Z","updated":"2018-04-04T04:51:51.004Z","comments":true,"path":"2017/03/06/ODL(OpenDayLight)-기본-튜토리얼-2-–-Impl-추가(Lithium-Version)/","link":"","permalink":"https://osujin.github.io/2017/03/06/ODL(OpenDayLight)-기본-튜토리얼-2-–-Impl-추가(Lithium-Version)/","excerpt":"","text":"기본 프로젝트 생성 뒤 추가 plugin(Impl module)을 추가할때 프로젝트를 새로 생성하여 만들어진 Impl 폴더를 복사해야하는 번거러움이 있다. 그리고 복사한뒤에 artifacetId , 폴더명 등을 바꾸려면 pom 파일 및 features 등록 과정이 필요한데 새로운 plugin을 추가하는 방법을 정리 해놓았다. 1&#46; 새로운 프로젝트 생성 튜토리얼1 내용 참고하여 새로운 ODL프로젝트를 생성한뒤 impl 폴더를 기존 프로젝트의 루트 경로에 복사하도록 한다. 새로운 프로젝트를 생성할때 groupId 값은 기존 생성된 프로젝트와 동일하게 만들어준다. artifactId 값은 임의로 정해주고 추구에 변경 하도록한다. 2&#46; Impl 폴더 복사 새로 생성한 프로젝트에서 Impl 폴더만 복사하여 기존 프로젝트로 옮긴다. 폴더명 수정 -&gt; 폴더명을 수정했으면 root pom.xml 파일에 아래와 같이 기존에 항목에 추가된 impl를 추가해준다. 1234567&lt;module&gt;api&lt;/module&gt; &lt;module&gt;[$추가된 Impl의 폴더명]&lt;/module&gt; &lt;module&gt;Impl&lt;/module&gt;&lt;module&gt;karaf&lt;/module&gt; &lt;module&gt;features&lt;/module&gt; &lt;module&gt;artifacts&lt;/module&gt; &lt;module&gt;it&lt;/module&gt; artifactId 수정 새로 생성한 Impl의 pom.xml 에서 artifactId 명을 수정해준다. 1234&lt;groupId&gt;org.opendaylight.hello&lt;/groupId&gt;&lt;artifactId&gt;notification-impl&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;bundle&lt;/packaging&gt; 그리고 dependency 에서 api 모듈의 정보를 가져오지 못해 문제가 발생하는데 기존 프로젝트의 api 모듈을 참조 하도록 수정해준다. 12345&lt;dependency&gt; &lt;groupId&gt;$&#123;project.groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;hello-api&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; 3&#46; feature 등록 feature 에 등록할때 수정이 필요한 파일은 총 2가지 이다. features의 pom.xml , features.xml features의 pom.xml dependency로 추가해줘야 하는게 2개 한쌍이다. 123456789101112&lt;dependency&gt; &lt;groupId&gt;$&#123;project.groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;Welcome&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;project.groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;Welcome&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;type&gt;xml&lt;/type&gt; &lt;classifier&gt;config&lt;/classifier&gt; &lt;/dependency&gt; features.xml * features/src/main/features/features.xml 12345&lt;feature name='odl-Welcome' version='$&#123;project.version&#125;' description='OpenDaylight :: Welcome'&gt; &lt;feature version='$&#123;mdsal.version&#125;'&gt;odl-mdsal-broker&lt;/feature&gt; &lt;feature version='$&#123;project.version&#125;'&gt;odl-mobigen-api&lt;/feature&gt; &lt;bundle&gt;mvn:org.opendaylight.mobigen/Welcome/&#123;&#123;VERSION&#125;&#125;&lt;;/bundle&gt;&lt;configfile finalname=\"$&#123;configfile.directory&#125;/Welcome.xml\"&gt;mvn:org.opendaylight.mobigen/Welcome/&#123;&#123;VERSION&#125;&#125;/xml/config&lt;/configfile&gt;&lt;/feature&gt; rest-api사용을 하기위해 REST에도 등록은 해준다. 마찬가지로 features.xml 파일에서 작업한다. 12345&lt;feature name='odl-mobigen-rest' version='$&#123;project.version&#125;' description='OpenDaylight :: mobigen :: REST'&gt; &lt;feature version=\"$&#123;project.version&#125;\"&gt;odl-Welcome&lt;/feature&gt; &lt;feature version=\"$&#123;project.version&#125;\"&gt;odl-Impl&lt;/feature&gt; &lt;feature version=\"$&#123;restconf.version&#125;\"&gt;odl-restconf&lt;/feature&gt;&lt;/feature&gt;","categories":[{"name":"OpenDayLight","slug":"OpenDayLight","permalink":"https://osujin.github.io/categories/OpenDayLight/"}],"tags":[]},{"title":"ODL(OpenDayLight) 기본 튜토리얼 #1 - 프로젝트 생성","slug":"ODL(OpenDayLight)-기본-튜토리얼-1---프로젝트-생성","date":"2017-03-06T06:17:01.000Z","updated":"2018-04-04T02:30:44.103Z","comments":true,"path":"2017/03/06/ODL(OpenDayLight)-기본-튜토리얼-1---프로젝트-생성/","link":"","permalink":"https://osujin.github.io/2017/03/06/ODL(OpenDayLight)-기본-튜토리얼-1---프로젝트-생성/","excerpt":"","text":"선행사항 maven 및 java 8 설치 선행 필수 ~/.m2/setting.xml 파일 수정 필수(ODL nexus repositroy 설정) -&gt;Development Environment Setup mvn project 생성1234$ mvn archetype:generate -DarchetypeGroupId=org.opendaylight.controller -DarchetypeArtifactId=opendaylight-startup-archetype \\-DarchetypeRepository=http://nexus.opendaylight.org/content/repositories/opendaylight.snapshot/ \\-DarchetypeCatalog=http://nexus.opendaylight.org/content/repositories/opendaylight.snapshot/archetype-catalog.xml \\-DarchetypeVersion=1.1.5-SNAPSHOT 프로젝트 생성 후 property 입력 Example123456Define value for property &apos;groupId&apos;: : org.opendaylight.helloDefine value for property &apos;artifactId&apos;: : helloDefine value for property &apos;version&apos;: 1.0-SNAPSHOTDefine value for property &apos;package&apos;: org.opendaylight.hello: :Define value for property &apos;classPrefix&apos;: helloDefine value for property &apos;copyright&apos;: : Yoyodyne, Inc. 생성된 프로젝트 구조 참고 : OpenDaylight Controller:MD-SAL:Startup Project Archetype","categories":[{"name":"OpenDayLight","slug":"OpenDayLight","permalink":"https://osujin.github.io/categories/OpenDayLight/"}],"tags":[]}]}